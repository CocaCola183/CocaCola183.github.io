<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kivi</title>
  <subtitle>没有什么远大理想，只是永远都不会满足而已</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://cocacola183.github.io/"/>
  <updated>2018-10-29T18:08:40.076Z</updated>
  <id>http://cocacola183.github.io/</id>
  
  <author>
    <name>kivi</name>
    <email>s_f_dragon@163.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>峨眉山</title>
    <link href="http://cocacola183.github.io/2018/10/28/shutterbug/%E5%B3%A8%E7%9C%89%E5%B1%B1/"/>
    <id>http://cocacola183.github.io/2018/10/28/shutterbug/峨眉山/</id>
    <published>2018-10-28T14:25:15.000Z</published>
    <updated>2018-10-29T18:08:40.076Z</updated>
    
    <content type="html"><![CDATA[<p>10月底唯一的一朵小野花</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/花.jpg" alt="花"></p>
<a id="more"></a>
<p>走山路才会看到的带着青苔的石阶，步行上山永远的风景</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/青苔石阶1.jpg" alt="青苔石阶1"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/青苔石阶2.jpg" alt="青苔石阶2"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/青苔石阶3.jpg" alt="青苔石阶3"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/青苔石阶4.jpg" alt="青苔石阶4"></p>
<p>很有特点的树</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/树1.jpg" alt="树1"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/树2.jpg" alt="树2"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/树3.jpg" alt="树3"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/树4.jpg" alt="树4"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/树5.jpg" alt="树5"></p>
<p>淡淡秋意</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/秋意1.jpg" alt="秋意1"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/秋意2.jpg" alt="秋意2"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/秋意3.jpg" alt="秋意3"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/秋意4.jpg" alt="秋意4"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/秋意5.jpg" alt="秋意5"></p>
<p>苔藓和石头的结合，总是很有特点</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/石头苔藓1.jpg" alt="石头苔藓1"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/石头苔藓2.jpg" alt="石头苔藓2"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/石头苔藓3.jpg" alt="石头苔藓3"></p>
<p>仙境一般的山雾，峨眉山的重头戏</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾1.jpg" alt="山雾1"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾2.jpg" alt="山雾2"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾3.jpg" alt="山雾3"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾4.jpg" alt="山雾4"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾5.jpg" alt="山雾5"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾6.jpg" alt="山雾6"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾7.jpg" alt="山雾7"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/山雾8.jpg" alt="山雾8"></p>
<p>夜爬没有灯，还是有点恐怖的</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/夜爬.jpg" alt="夜爬"></p>
<p>但是夜景也挺美</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/夜景1.jpg" alt="夜景1"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/夜景2.jpg" alt="夜景2"></p>
<p>凌晨接着爬</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/凌晨.jpg" alt="凌晨"></p>
<p>戏猴的真实场景</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/戏猴.jpg" alt="戏猴"></p>
<p>8块100斤，没有同情，只有感叹，你我都有负此重担的日子，金顶在坐，却不是我们的方向</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/8块100斤.jpg" alt="8块100斤"></p>
<p>还有看不完的美景</p>
<p><img src="/2018/10/28/shutterbug/峨眉山/段面.jpg" alt="段面"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/夹缝1.jpg" alt="夹缝1"></p>
<p><img src="/2018/10/28/shutterbug/峨眉山/夹缝2.jpg" alt="夹缝2"></p>
<p>唯一的遗憾可能就是没有和一起徒步登山的俄罗斯小姐姐留个念</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;10月底唯一的一朵小野花&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2018/10/28/shutterbug/峨眉山/花.jpg&quot; alt=&quot;花&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="shutterbug" scheme="http://cocacola183.github.io/categories/shutterbug/"/>
    
    
      <category term="shutterbug" scheme="http://cocacola183.github.io/tags/shutterbug/"/>
    
  </entry>
  
  <entry>
    <title>Linux的CPU,内存,磁盘IO,网络压力测试方法</title>
    <link href="http://cocacola183.github.io/2017/08/07/linux/Linux%E7%9A%84CPU-%E5%86%85%E5%AD%98-%E7%A3%81%E7%9B%98IO-%E7%BD%91%E7%BB%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"/>
    <id>http://cocacola183.github.io/2017/08/07/linux/Linux的CPU-内存-磁盘IO-网络压力测试方法/</id>
    <published>2017-08-07T15:07:36.000Z</published>
    <updated>2017-08-12T09:23:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="适用范围"><a href="#适用范围" class="headerlink" title="适用范围"></a>适用范围</h2><p>centos</p>
<h2 id="CPU和内存"><a href="#CPU和内存" class="headerlink" title="CPU和内存"></a>CPU和内存</h2><h3 id="stress"><a href="#stress" class="headerlink" title="stress"></a>stress</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo yum install stress -y</div></pre></td></tr></table></figure>
<a id="more"></a>
<h4 id="命令介绍"><a href="#命令介绍" class="headerlink" title="命令介绍"></a>命令介绍</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># stress</div><div class="line">`stress&apos; imposes certain types of compute stress on your system</div><div class="line"></div><div class="line">Usage: stress [OPTION [ARG]] ...</div><div class="line"> -?, --help         show this help statement</div><div class="line">     --version      show version statement</div><div class="line"> -v, --verbose      be verbose</div><div class="line"> -q, --quiet        be quiet</div><div class="line"> -n, --dry-run      show what would have been done</div><div class="line"> -t, --timeout N    timeout after N seconds</div><div class="line">     --backoff N    wait factor of N microseconds before work starts</div><div class="line"> -c, --cpu N        spawn N workers spinning on sqrt()</div><div class="line"> -i, --io N         spawn N workers spinning on sync()</div><div class="line"> -m, --vm N         spawn N workers spinning on malloc()/free()</div><div class="line">     --vm-bytes B   malloc B bytes per vm worker (default is 256MB)</div><div class="line">     --vm-stride B  touch a byte every B bytes (default is 4096)</div><div class="line">     --vm-hang N    sleep N secs before free (default none, 0 is inf)</div><div class="line">     --vm-keep      redirty memory instead of freeing and reallocating</div><div class="line"> -d, --hdd N        spawn N workers spinning on write()/unlink()</div><div class="line">     --hdd-bytes B  write B bytes per hdd worker (default is 1GB)</div><div class="line"></div><div class="line">Example: stress --cpu 8 --io 4 --vm 2 --vm-bytes 128M --timeout 10s</div><div class="line"></div><div class="line">Note: Numbers may be suffixed with s,m,h,d,y (time) or B,K,M,G (size).</div></pre></td></tr></table></figure>
<h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><p>stress可以从cpu，内存，磁盘io性能等指标综合起来，以系统负载为最终指标，来衡量单机的性能。这个命令更适合去评测综合能力，cpu，内存和磁盘io的同时负载能力</p>
<h4 id="使用命令"><a href="#使用命令" class="headerlink" title="使用命令"></a>使用命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">uptime</div><div class="line">stress -c 4 -i 1 -m 1 --vm-bytes 128M -t 10s</div><div class="line">uptime</div></pre></td></tr></table></figure>
<h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><h3 id="dd"><a href="#dd" class="headerlink" title="dd"></a>dd</h3><h4 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line">Usage: dd [OPERAND]...</div><div class="line">  or:  dd OPTION</div><div class="line">Copy a file, converting and formatting according to the operands.</div><div class="line"></div><div class="line">  bs=BYTES        read and write BYTES bytes at a time (also see ibs=,obs=)</div><div class="line">  cbs=BYTES       convert BYTES bytes at a time</div><div class="line">  conv=CONVS      convert the file as per the comma separated symbol list</div><div class="line">  count=N         copy only N input blocks</div><div class="line">  ibs=BYTES       read BYTES bytes at a time (default: 512)</div><div class="line">  if=FILE         read from FILE instead of stdin</div><div class="line">  iflag=FLAGS     read as per the comma separated symbol list</div><div class="line">  obs=BYTES       write BYTES bytes at a time (default: 512)</div><div class="line">  of=FILE         write to FILE instead of stdout</div><div class="line">  oflag=FLAGS     write as per the comma separated symbol list</div><div class="line">  seek=BLOCKS     skip BLOCKS obs-sized blocks at start of output</div><div class="line">  skip=BLOCKS     skip BLOCKS ibs-sized blocks at start of input</div><div class="line">  status=WHICH    WHICH info to suppress outputting to stderr;</div><div class="line">                  &apos;noxfer&apos; suppresses transfer stats, &apos;none&apos; suppresses all</div><div class="line"></div><div class="line">BLOCKS and BYTES may be followed by the following multiplicative suffixes:</div><div class="line">c =1, w =2, b =512, kB =1000, K =1024, MB =1000*1000, M =1024*1024, xM =M</div><div class="line">GB =1000*1000*1000, G =1024*1024*1024, and so on for T, P, E, Z, Y.</div><div class="line"></div><div class="line">Each CONV symbol may be:</div><div class="line"></div><div class="line">  ascii     from EBCDIC to ASCII</div><div class="line">  ebcdic    from ASCII to EBCDIC</div><div class="line">  ibm       from ASCII to alternate EBCDIC</div><div class="line">  block     pad newline-terminated records with spaces to cbs-size</div><div class="line">  unblock   replace trailing spaces in cbs-size records with newline</div><div class="line">  lcase     change upper case to lower case</div><div class="line">  nocreat   do not create the output file</div><div class="line">  excl      fail if the output file already exists</div><div class="line">  notrunc   do not truncate the output file</div><div class="line">  ucase     change lower case to upper case</div><div class="line">  sparse    try to seek rather than write the output for NUL input blocks</div><div class="line">  swab      swap every pair of input bytes</div><div class="line">  noerror   continue after read errors</div><div class="line">  sync      pad every input block with NULs to ibs-size; when used</div><div class="line">            with block or unblock, pad with spaces rather than NULs</div><div class="line">  fdatasync  physically write output file data before finishing</div><div class="line">  fsync     likewise, but also write metadata</div><div class="line"></div><div class="line">Each FLAG symbol may be:</div><div class="line"></div><div class="line">  append    append mode (makes sense only for output; conv=notrunc suggested)</div><div class="line">  direct    use direct I/O for data</div><div class="line">  directory  fail unless a directory</div><div class="line">  dsync     use synchronized I/O for data</div><div class="line">  sync      likewise, but also for metadata</div><div class="line">  fullblock  accumulate full blocks of input (iflag only)</div><div class="line">  nonblock  use non-blocking I/O</div><div class="line">  noatime   do not update access time</div><div class="line">  noctty    do not assign controlling terminal from file</div><div class="line">  nofollow  do not follow symlinks</div><div class="line">  count_bytes  treat &apos;count=N&apos; as a byte count (iflag only)</div><div class="line"></div><div class="line">Sending a USR1 signal to a running `dd&apos; process makes it</div><div class="line">print I/O statistics to standard error and then resume copying.</div><div class="line"></div><div class="line">  $ dd if=/dev/zero of=/dev/null&amp; pid=$!</div><div class="line">  $ kill -USR1 $pid; sleep 1; kill $pid</div><div class="line">  18335302+0 records in</div><div class="line">  18335302+0 records out</div><div class="line">  9387674624 bytes (9.4 GB) copied, 34.6279 seconds, 271 MB/s</div><div class="line"></div><div class="line">Options are:</div><div class="line"></div><div class="line">      --help     display this help and exit</div><div class="line">      --version  output version information and exit</div><div class="line"></div><div class="line">Report dd bugs to bug-coreutils@gnu.org</div><div class="line">GNU coreutils home page: &lt;http://www.gnu.org/software/coreutils/&gt;</div><div class="line">General help using GNU software: &lt;http://www.gnu.org/gethelp/&gt;</div><div class="line">For complete documentation, run: info coreutils &apos;dd invocation&apos;</div></pre></td></tr></table></figure>
<p>上面说明有很多，通畅情况下，用下面的命令去测试磁盘的读写性能</p>
<h4 id="写性能测试"><a href="#写性能测试" class="headerlink" title="写性能测试"></a>写性能测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">time dd if=/dev/xvda1 of=/test.disk bs=8k count=300000</div></pre></td></tr></table></figure>
<p>用dd命令进行测试，以每次写入8k的数据，执行300000次，time命令显示执行过程的时间，执行完成后生成/test.disk文件，大小为2.5G</p>
<p>上面的命令其实是会将数据写入到文件系统缓存（系统默认操作，提高效率），而且是磁盘连续写，所以理论上是一个磁盘写入速度的极限值，如果是直接写入到磁盘，可以添加参数<code>oflag</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">time dd if=/dev/xvda1 of=/test.disk bs=8k count=300000 oflag=direct</div></pre></td></tr></table></figure></p>
<h4 id="读性能测试"><a href="#读性能测试" class="headerlink" title="读性能测试"></a>读性能测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">time dd if=/test.disk of=/dev/xvda1 bs=8k</div></pre></td></tr></table></figure>
<h4 id="读写联合测试"><a href="#读写联合测试" class="headerlink" title="读写联合测试"></a>读写联合测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">time dd if=/test.disk of=/tmp/test.disk2 bs=8k</div></pre></td></tr></table></figure>
<h3 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h3><h4 id="显示所有设备负载情况"><a href="#显示所有设备负载情况" class="headerlink" title="显示所有设备负载情况"></a>显示所有设备负载情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iostat</div></pre></td></tr></table></figure>
<p><strong>cpu属性值说明：</strong></p>
<ul>
<li>%user：CPU处在用户模式下的时间百分比。</li>
<li>%nice：CPU处在带NICE值的用户模式下的时间百分比。</li>
<li>%system：CPU处在系统模式下的时间百分比。</li>
<li>%iowait：CPU等待输入输出完成时间的百分比。</li>
<li>%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。</li>
<li>%idle：CPU空闲时间百分比。</li>
</ul>
<blockquote>
<p>注意：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。</p>
</blockquote>
<p><strong>disk属性值说明：</strong></p>
<ul>
<li>rrqm/s: 每秒进行 merge 的读操作数目。即 rmerge/s</li>
<li>wrqm/s: 每秒进行 merge 的写操作数目。即 wmerge/s</li>
<li>r/s: 每秒完成的读 I/O 设备次数。即 rio/s</li>
<li>w/s: 每秒完成的写 I/O 设备次数。即 wio/s</li>
<li>rsec/s: 每秒读扇区数。即 rsect/s</li>
<li>wsec/s: 每秒写扇区数。即 wsect/s</li>
<li>rkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。</li>
<li>wkB/s: 每秒写K字节数。是 wsect/s 的一半。</li>
<li>avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。</li>
<li>avgqu-sz: 平均I/O队列长度。</li>
<li>await: 平均每次设备I/O操作的等待时间 (毫秒)。</li>
<li>svctm: 平均每次设备I/O操作的服务时间 (毫秒)。</li>
<li>%util: 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比</li>
</ul>
<blockquote>
<p>备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待</p>
</blockquote>
<h4 id="定时显示所有信息"><a href="#定时显示所有信息" class="headerlink" title="定时显示所有信息"></a>定时显示所有信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 每2s打印一次，一共打印3次</span></div><div class="line">iostat 2 3</div></pre></td></tr></table></figure>
<h4 id="查看TPS和吞吐量"><a href="#查看TPS和吞吐量" class="headerlink" title="查看TPS和吞吐量"></a>查看TPS和吞吐量</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iostat -d -k 1 1</div></pre></td></tr></table></figure>
<p>说明:</p>
<ul>
<li>tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。“一次传输”请求的大小是未知的。</li>
<li>kB_read/s：每秒从设备（drive expressed）读取的数据量；</li>
<li>kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；</li>
<li>kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量；</li>
</ul>
<h4 id="查看设备使用率（-util）和响应时间（await）"><a href="#查看设备使用率（-util）和响应时间（await）" class="headerlink" title="查看设备使用率（%util）和响应时间（await）"></a>查看设备使用率（%util）和响应时间（await）</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iostat -d -x -k 1 1</div></pre></td></tr></table></figure>
<p>rrqm/s： 每秒进行 merge 的读操作数目.即 delta(rmerge)/s<br>wrqm/s： 每秒进行 merge 的写操作数目.即 delta(wmerge)/s<br>r/s： 每秒完成的读 I/O 设备次数.即 delta(rio)/s<br>w/s： 每秒完成的写 I/O 设备次数.即 delta(wio)/s<br>rsec/s： 每秒读扇区数.即 delta(rsect)/s<br>wsec/s： 每秒写扇区数.即 delta(wsect)/s<br>rkB/s： 每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算)<br>wkB/s： 每秒写K字节数.是 wsect/s 的一半.(需要计算)<br>avgrq-sz：平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio)<br>avgqu-sz：平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒).<br>await： 平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio)<br>svctm： 平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio)<br>%util： 一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为use的单位为毫秒)<br>如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。 idle小于70% IO压力就较大了，一般读取速度有较多的wait。 同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比，高过30%时IO压力高)。</p>
<p>另外 await 的参数也要多和 svctm 来参考。差的过高就一定有 IO 的问题。</p>
<p>avgqu-sz 也是个做 IO 调优时需要注意的地方，这个就是直接每次操作的数据的大小，如果次数多，但数据拿的小的话，其实 IO 也会很小。如果数据拿的大，才IO 的数据会高。也可以通过 avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s。也就是讲，读定速度是这个来决定的。</p>
<p>svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了)，svctm 的大小一般和磁盘性能有关，CPU/内存的负荷也会对其有影响，请求过多也会间接导致 svctm 的增加。await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。</p>
<p>队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。</p>
<p>形象的比喻：<br>r/s+w/s 类似于交款人的总数<br>平均队列长度(avgqu-sz)类似于单位时间里平均排队人的个数<br>平均服务时间(svctm)类似于收银员的收款速度<br>平均等待时间(await)类似于平均每人的等待时间<br>平均I/O数据(avgrq-sz)类似于平均每人所买的东西多少<br>I/O 操作率 (%util)类似于收款台前有人排队的时间比例<br>设备IO操作:总IO(io)/s = r/s(读) +w/s(写)</p>
<p>平均等待时间=单个I/O服务器时间*(1+2+…+请求总数-1)/请求总数</p>
<p>每秒发出的I/0请求很多,但是平均队列就4,表示这些请求比较均匀,大部分处理还是比较及时。</p>
<h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><h3 id="iperf"><a href="#iperf" class="headerlink" title="iperf"></a>iperf</h3><h4 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a>测试方法</h4><p>两台机器，先安装<code>iperf</code>工具，然后一台机器以<code>server</code>方式启动，另外一台以<code>client</code>方式运行，进行网络压力测试</p>
<h4 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">-s 以server模式启动，eg：iperf -s</div><div class="line">-c 以client模式启动，host是server端地址，eg：iperf -c 1.1.1.1</div><div class="line"></div><div class="line">通用参数</div><div class="line">-f [k|m|K|M] 分别表示以Kbits, Mbits, KBytes, MBytes显示报告，默认以Mbits为单位,eg:iperf -c 222.35.11.23 -f K</div><div class="line"></div><div class="line">-i sec 以秒为单位显示报告间隔，eg:iperf -c 222.35.11.23 -i 2</div><div class="line">iperf是client端向server端发送数据</div><div class="line">server端显示的是接收速率，最好加i参数，进行速率跟踪</div><div class="line">client 显示的是发送速率</div><div class="line">server 显示接收速率</div><div class="line"></div><div class="line">-l 缓冲区大小，默认是8KB,eg: iperf -c 1.1.1.1 -l 16 可以使用不同的包长，进行测试</div><div class="line"></div><div class="line">-m 显示tcp最大mtu值</div><div class="line">-o 将报告和错误信息输出到文件 eg: iperf -c 1.1.1.1 -o c:iperflog.txt</div><div class="line">-p 指定服务器端使用的端口或客户端所连接的端口 eg: iperf -s -p 9999;iperf -c 222.35.11.23 -p 9999</div><div class="line"></div><div class="line">-u 使用udp协议， 测试htb的时候最好用udp，udp通信开销小，测试的带宽更准确</div><div class="line">-w 指定TCP窗口大小，默认是8KB，如果窗口太小，有可能丢包</div><div class="line"></div><div class="line">-B 绑定一个主机地址或接口（当主机有多个地址或接口时使用该参数）</div><div class="line">-C 兼容旧版本（当server端和client端版本不一样时使用）</div><div class="line">-M 设定TCP数据包的最大mtu值</div><div class="line">-N 设定TCP不延时</div><div class="line">-V 传输ipv6数据包</div><div class="line"></div><div class="line">server专用参数</div><div class="line">-D 以服务方式运行ipserf，eg: iperf -s -D</div><div class="line">-R 停止iperf服务，针对-D，eg: iperf -s -R</div><div class="line"></div><div class="line">client端专用参数</div><div class="line">-d 同时进行双向传输测试</div><div class="line">-n 指定传输的字节数，eg: iperf -c 222.35.11.23 -n 100000</div><div class="line">-r 单独进行双向传输测试</div><div class="line"></div><div class="line">-b 指定发送带宽，默认是1Mbit/s</div><div class="line"></div><div class="line">在测试qos的时候，这是最有用的参数。</div><div class="line">-t 测试时间，默认10秒, eg: iperf -c 222.35.11.23 -t 5</div><div class="line"></div><div class="line">默认是10s</div><div class="line"></div><div class="line">-F 指定需要传输的文件</div><div class="line">-T 指定ttl值</div></pre></td></tr></table></figure>
<p>###@ 使用示例<br>服务端：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iperf -s -u</div></pre></td></tr></table></figure></p>
<p>-s 标记此端为服务端<br>-u 标记自己为UDP监听<br>-p 指定自己监听端口</p>
<p>客户端：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iperf -c 1.1.1.1 -i 1 -u -t 60 -F /root/a.zip -P 5</div></pre></td></tr></table></figure></p>
<p>-c 标记自己为客户端<br>-i 设定输出值间隔<br>-u 使用传输协议为UDP<br>-t 设定测试时间为60秒<br>-F 指定传输文件(该项可有可无)<br>-P 指定进程数，如果设置为5，那么也就相当与对端建立五个连接</p>
<p>注意事项：<br>1.发包测试需要分为UDP测试与TCP测试，其中服务端需要用-u命令去区分监听协议。<br>2.TCP协议测试不能计算出时延与丢包率，而且还不能指定发送带宽。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.cyberciti.biz/faq/stress-test-linux-unix-server-with-stress-ng/" target="_blank" rel="external">How To Stress Test CPU and Memory (VM) On a Linux and Unix With Stress-ng</a><br><a href="http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/iostat.html" target="_blank" rel="external">iostat 监视I/O子系统</a>，这个连接下面有非常多实用的Linux工具使用说明<br><a href="http://blog.csdn.net/evenness/article/details/7371845" target="_blank" rel="external">使用iperf测试网络性能</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;适用范围&quot;&gt;&lt;a href=&quot;#适用范围&quot; class=&quot;headerlink&quot; title=&quot;适用范围&quot;&gt;&lt;/a&gt;适用范围&lt;/h2&gt;&lt;p&gt;centos&lt;/p&gt;
&lt;h2 id=&quot;CPU和内存&quot;&gt;&lt;a href=&quot;#CPU和内存&quot; class=&quot;headerlink&quot; title=&quot;CPU和内存&quot;&gt;&lt;/a&gt;CPU和内存&lt;/h2&gt;&lt;h3 id=&quot;stress&quot;&gt;&lt;a href=&quot;#stress&quot; class=&quot;headerlink&quot; title=&quot;stress&quot;&gt;&lt;/a&gt;stress&lt;/h3&gt;&lt;h4 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h4&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;sudo yum install stress -y&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="linux" scheme="http://cocacola183.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://cocacola183.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>nginx流量复制</title>
    <link href="http://cocacola183.github.io/2017/08/06/nginx/nginx%E6%B5%81%E9%87%8F%E5%A4%8D%E5%88%B6/"/>
    <id>http://cocacola183.github.io/2017/08/06/nginx/nginx流量复制/</id>
    <published>2017-08-06T15:00:11.000Z</published>
    <updated>2017-08-06T15:41:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="参考连接"><a href="#参考连接" class="headerlink" title="参考连接"></a>参考连接</h2><p><a href="http://www.crackedzone.com/testing-service-with-nginx-copy-request.html" target="_blank" rel="external">通过Nginx拷贝请求流量到测试环境测试</a></p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>nginx没有内置模块可以实现流量复制的功能，需要借助lua脚本实现流量复制的功能</p>
<a id="more"></a>
<h2 id="依赖安装和下载脚本"><a href="#依赖安装和下载脚本" class="headerlink" title="依赖安装和下载脚本"></a>依赖安装和下载脚本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 首先download需要的nginx脚本，然后放到/opt/目录下（命名为nginx），并创建lib文件夹</span></div><div class="line"></div><div class="line">cd /opt/nginx/lib</div><div class="line"></div><div class="line">wget https://github.com/openresty/lua-nginx-module/archive/v0.10.9rc8.tar.gz</div><div class="line">mv v0.10.9rc8.tar.gz lua-nginx-module-v0.10.9rc8.tar.gz</div><div class="line"></div><div class="line">wget https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz</div><div class="line">mv v0.3.0.tar.gz ngx_devel_kit-v0.3.0.tar.gz</div><div class="line"></div><div class="line">wget https://github.com/openresty/headers-more-nginx-module/archive/v0.32.tar.gz</div><div class="line">mv v0.32.tar.gz headers-more-nginx-module-v0.32.tar.gz</div><div class="line"></div><div class="line">wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gz</div><div class="line">tar zxvf pcre-8.38.tar.gz</div><div class="line">cd pcre-8.38</div><div class="line">./configure --prefix=/opt/nginx/lib/pcre-8.38</div><div class="line">make</div><div class="line">make install</div><div class="line"></div><div class="line">wget https://zlib.net/zlib-1.2.11.tar.gz</div><div class="line">tar zxvf zlib-1.2.11.tar.gz</div><div class="line">cd zlib-1.2.11</div><div class="line">./configure --prefix=/opt/nginx/lib/zlib-1.2.11</div><div class="line">make</div><div class="line">make install</div><div class="line"></div><div class="line">wget http://luajit.org/download/LuaJIT-2.0.5.tar.gz</div><div class="line">tar zxvf LuaJIT-2.0.5.tar.gz</div><div class="line">cd LuaJIT-2.0.5</div><div class="line">make</div><div class="line">make install PREFIX=/opt/nginx/lib/LuaJIT-2.0.5</div><div class="line">export LUAJIT_LIB=/opt/nginx/lib/LuaJIT-2.0.5/lib</div><div class="line">export LUAJIT_INC=/opt/nginx/lib/LuaJIT-2.0.5/include/luajit-2.0</div><div class="line"></div><div class="line">cd /opt/nginx/lib</div><div class="line">tar zxvf lua-nginx-module-v0.10.9rc8.tar.gz</div><div class="line">tar zxvf ngx_devel_kit-v0.3.0.tar.gz</div><div class="line">tar zxvf headers-more-nginx-module-v0.32.tar.gz</div><div class="line"></div><div class="line">cd /opt/nginx</div><div class="line">./configure \</div><div class="line">--user=nginx --group=nginx --prefix=/opt/nginx \</div><div class="line">--with-http_stub_status_module \</div><div class="line">--with-http_ssl_module \</div><div class="line">--with-http_gzip_static_module \</div><div class="line">--with-http_realip_module \</div><div class="line">--with-http_addition_module \</div><div class="line">--with-pcre=/opt/nginx/lib/pcre-8.38 \</div><div class="line">--with-zlib=/opt/nginx/lib/zlib-1.2.11 \</div><div class="line">--with-ld-opt="-Wl,-rpath,$LUAJIT_LIB" \</div><div class="line">--add-module=/opt/nginx/lib/ngx_devel_kit-0.3.0 \</div><div class="line">--add-module=/opt/nginx/lib/headers-more-nginx-module-0.32 \</div><div class="line">--add-module=/opt/nginx/lib/lua-nginx-module-0.10.9rc8</div><div class="line">make</div></pre></td></tr></table></figure>
<h2 id="lua脚本"><a href="#lua脚本" class="headerlink" title="lua脚本"></a>lua脚本</h2><p>创建文件: <code>/opt/nginx/conf/lua/copy_req.lua</code></p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">local</span> res1, res2, action</div><div class="line">action = ngx.var.request_method</div><div class="line"><span class="keyword">if</span> action == <span class="string">"POST"</span> <span class="keyword">then</span></div><div class="line">        arry = &#123;method = ngx.HTTP_POST, body = ngx.req.read_body()&#125;</div><div class="line"><span class="keyword">else</span></div><div class="line">        arry = &#123;method = ngx.HTTP_GET&#125;</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> ngx.var.svr == <span class="string">"on"</span> <span class="keyword">then</span></div><div class="line">        res1, res2 = ngx.location.capture_multi &#123;</div><div class="line">                &#123; <span class="string">"/product"</span> .. ngx.var.request_uri , arry&#125;,</div><div class="line">                &#123; <span class="string">"/test"</span> .. ngx.var.request_uri , arry&#125;,</div><div class="line">        &#125;</div><div class="line"><span class="keyword">else</span></div><div class="line">        res1, res2 = ngx.location.capture_multi &#123;</div><div class="line">                &#123; <span class="string">"/product"</span> .. ngx.var.request_uri , arry&#125;,</div><div class="line">        &#125;</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> res1.<span class="built_in">status</span> == ngx.HTTP_OK <span class="keyword">then</span></div><div class="line">        <span class="keyword">local</span> header_list = &#123;<span class="string">"Content-Length"</span>, <span class="string">"Content-Type"</span>, <span class="string">"Content-Encoding"</span>, <span class="string">"Accept-Ranges"</span>, <span class="string">"set-cookie"</span>&#125;</div><div class="line">        <span class="keyword">for</span> _, i <span class="keyword">in</span> <span class="built_in">ipairs</span>(header_list) <span class="keyword">do</span></div><div class="line">                <span class="keyword">if</span> res1.header[i] <span class="keyword">then</span></div><div class="line">                        ngx.header[i] = res1.header[i]</div><div class="line">                <span class="keyword">end</span></div><div class="line">        <span class="keyword">end</span></div><div class="line">        ngx.say(res1.body)</div><div class="line"><span class="keyword">else</span></div><div class="line">        <span class="comment">-- ngx.status = ngx.HTTP_NOT_FOUND</span></div><div class="line">        <span class="comment">-- ngx.say(res1.body)</span></div><div class="line">        ngx.<span class="built_in">exit</span>(ngx.HTTP_NOT_FOUND) <span class="comment">-- 这里跟原文有点改动，我使用的1.10.0，需要这么写才能正常返回404页面</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<h2 id="nginx配置"><a href="#nginx配置" class="headerlink" title="nginx配置"></a>nginx配置</h2><figure class="highlight nginx"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="section">http</span> &#123;</div><div class="line"></div><div class="line">    <span class="comment"># 其他配置</span></div><div class="line"></div><div class="line">    <span class="attribute">upstream</span> product &#123;</div><div class="line">        <span class="attribute">server</span>  <span class="number">127.0.0.1:8001</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="attribute">upstream</span> test &#123;</div><div class="line">        <span class="attribute">server</span>  <span class="number">127.0.0.1:8002</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="section">server</span> &#123;</div><div class="line">      <span class="attribute">listen</span>       <span class="number">8000</span>;</div><div class="line">      <span class="attribute">server_name</span>  test;</div><div class="line"></div><div class="line">	    <span class="attribute">location</span> <span class="regexp">~* ^/product</span> &#123;</div><div class="line">            <span class="attribute">log_subrequest</span> <span class="literal">on</span>;</div><div class="line">            <span class="attribute">rewrite</span><span class="regexp"> ^/product(.*)$</span> <span class="variable">$1</span> <span class="literal">break</span>;</div><div class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</div><div class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</div><div class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</div><div class="line">            <span class="attribute">proxy_pass</span> http://product;</div><div class="line">            <span class="attribute">access_log</span> logs/product-upstream.log;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"> 	      <span class="attribute">location</span> <span class="regexp">~* ^/test</span> &#123;</div><div class="line">            <span class="attribute">log_subrequest</span> <span class="literal">on</span>;</div><div class="line">            <span class="attribute">rewrite</span><span class="regexp"> ^/test(.*)$</span> <span class="variable">$1</span> <span class="literal">break</span>;</div><div class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</div><div class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</div><div class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</div><div class="line">            <span class="attribute">proxy_pass</span> http://test;</div><div class="line">            <span class="attribute">access_log</span> logs/test-upstream.log;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="attribute">location</span> <span class="regexp">~* ^/(.*)$</span> &#123;</div><div class="line">            <span class="attribute">set</span> <span class="variable">$svr</span>     		<span class="string">"on"</span>;	<span class="comment">#开启或关闭copy功能</span></div><div class="line">            <span class="attribute">content_by_lua_file</span>   	<span class="string">"conf/lua/copy_req.lua"</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="attribute">error_page</span>   <span class="number">404</span>  /<span class="number">404</span>.html;</div><div class="line">            <span class="attribute">location</span> = /<span class="number">404</span>.html &#123;</div><div class="line">            <span class="attribute">root</span> html;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;</div><div class="line">        <span class="attribute">location</span> = /50x.html &#123;</div><div class="line">            <span class="attribute">root</span>   html;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>启动nginx，访问8000端口，负责响应请求的是8001端口的服务，所有打到8001端口的服务的post请求也会打到8002端口的服务上，这就通过nginx实现了流量复制的功能。上面只是demo，实际使用中可以根据实际条件调整·</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;参考连接&quot;&gt;&lt;a href=&quot;#参考连接&quot; class=&quot;headerlink&quot; title=&quot;参考连接&quot;&gt;&lt;/a&gt;参考连接&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://www.crackedzone.com/testing-service-with-nginx-copy-request.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;通过Nginx拷贝请求流量到测试环境测试&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;原理&quot;&gt;&lt;a href=&quot;#原理&quot; class=&quot;headerlink&quot; title=&quot;原理&quot;&gt;&lt;/a&gt;原理&lt;/h2&gt;&lt;p&gt;nginx没有内置模块可以实现流量复制的功能，需要借助lua脚本实现流量复制的功能&lt;/p&gt;
    
    </summary>
    
      <category term="nginx" scheme="http://cocacola183.github.io/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://cocacola183.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>mongodb生产部署建议</title>
    <link href="http://cocacola183.github.io/2017/07/10/mongo/mongodb%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E5%BB%BA%E8%AE%AE/"/>
    <id>http://cocacola183.github.io/2017/07/10/mongo/mongodb生产部署建议/</id>
    <published>2017-07-10T03:34:35.000Z</published>
    <updated>2017-08-04T00:26:53.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MongoDB二进制文件"><a href="#MongoDB二进制文件" class="headerlink" title="MongoDB二进制文件"></a>MongoDB二进制文件</h2><h3 id="支持的运行平台"><a href="#支持的运行平台" class="headerlink" title="支持的运行平台"></a>支持的运行平台</h3><ul>
<li><a href="https://docs.mongodb.com/manual/administration/production-notes/#x86-64" target="_blank" rel="external">x86_64</a></li>
<li><a href="https://docs.mongodb.com/manual/administration/production-notes/#arm64" target="_blank" rel="external">ARM64</a></li>
<li><a href="https://docs.mongodb.com/manual/administration/production-notes/#ppc64le-mongodb-enterprise-edition" target="_blank" rel="external">PPC64LE (MongoDB Enterprise Edition)</a></li>
<li><a href="https://docs.mongodb.com/manual/administration/production-notes/#s390x-mongodb-enterprise-edition" target="_blank" rel="external">s390x (MongoDB Enterprise Edition)</a></li>
</ul>
<a id="more"></a>
<h4 id="推荐的运行平台"><a href="#推荐的运行平台" class="headerlink" title="推荐的运行平台"></a>推荐的运行平台</h4><ul>
<li>Amazon Linux</li>
<li>Debian 7.1</li>
<li>RHEL / CentOS 6.2+</li>
<li>SLES 11+</li>
<li>Ubuntu LTS 12.04</li>
<li>Ubuntu LTS 14.04</li>
<li>Windows Server 2012 &amp; 2012 R2</li>
</ul>
<h4 id="推荐mongodb最新的release版本"><a href="#推荐mongodb最新的release版本" class="headerlink" title="推荐mongodb最新的release版本"></a>推荐mongodb最新的release版本</h4><h2 id="MongoDB-dbpath"><a href="#MongoDB-dbpath" class="headerlink" title="MongoDB dbpath"></a>MongoDB dbpath</h2><h3 id="并发性（基于不同的数据库引擎的比较）"><a href="#并发性（基于不同的数据库引擎的比较）" class="headerlink" title="并发性（基于不同的数据库引擎的比较）"></a>并发性（基于不同的数据库引擎的比较）</h3><h4 id="MMAPv1"><a href="#MMAPv1" class="headerlink" title="MMAPv1"></a>MMAPv1</h4><p>3.0之后的改动：3.0之后，MongoDB MMapv1提供文档级别的数据库锁：所有的集合都有一个唯一的读写锁，这意味着不同的集合可以同时执行更新操作</p>
<p>在2.2到2.6之间，每个数据库都有一个读写锁，允许并发读操作，但每个database同一时刻只能有一个写操作。在更早的版本中，在一个mongod进程中，所有的写操作抢占一个写锁</p>
<h4 id="WiredTiger"><a href="#WiredTiger" class="headerlink" title="WiredTiger"></a>WiredTiger</h4><p>wt单文档支持并发读写，客户端可在写操作执行期间进行读取操作，不同的线程也可以同时去修改一个集合的某一条数据</p>
<h2 id="Data-Consistency-数据一致性"><a href="#Data-Consistency-数据一致性" class="headerlink" title="Data Consistency(数据一致性)"></a>Data Consistency(数据一致性)</h2><h3 id="Journaling-日志"><a href="#Journaling-日志" class="headerlink" title="Journaling(日志)"></a>Journaling(日志)</h3><p>MongoDB的日志持久化在磁盘，并且使用的是预写式日志。如果遇到意外故障（例如断电），日志信息保证了MongoDB可以迅速恢复记录在日志中的但还没有记录到数据文件中的写操作。</p>
<h3 id="Read-Concern-数据读策略"><a href="#Read-Concern-数据读策略" class="headerlink" title="Read Concern(数据读策略)"></a>Read Concern(数据读策略)</h3><p><a href="http://www.mongoing.com/archives/3403" target="_blank" rel="external">这里</a>详细说明了数据度策略是什么以及解决的问题，以及<code>readConcern</code>和<code>readPreference</code>的比较。这里简单说明下：</p>
<blockquote><p>readConcern 的初衷在于解决『脏读』的问题，比如用户从 MongoDB 的 primary 上读取了某一条数据，但这条数据并没有同步到大多数节点，然后 primary 就故障了，重新恢复后 这个primary 节点会将未同步到大多数节点的数据回滚掉，导致用户读到了『脏数据』。</p>
<p>当指定 readConcern 级别为 majority 时，能保证用户读到的数据『已经写入到大多数节点』，而这样的数据肯定不会发生回滚，避免了脏读的问题。</p>
<p>需要注意的是，readConcern 能保证读到的数据『不会发生回滚』，但并不能保证读到的数据是最新的，这个官网上也有说明。</p>
<blockquote>
<p>Regardless of the read concern level, the most recent data on a node may not reflect the most recent version of the data in the system.</p>
</blockquote>
<p>有用户误以为，readConcern 指定为 majority 时，客户端会从大多数的节点读取数据，然后返回最新的数据。</p>
<p>实际上并不是这样，无论何种级别的 readConcern，客户端都只会从『某一个确定的节点』（具体是哪个节点由 readPreference 决定）读取数据，该节点根据自己看到的同步状态视图，只会返回已经同步到大多数节点的数据。</p>
<footer><strong>mongodb中文社区</strong><cite><a href="http://www.mongoing.com/archives/3403" target="_blank" rel="external">www.mongoing.com/archives/3403</a></cite></footer></blockquote>
<p>注意，读策略是MongoDB3.2加入的新特性，如果要使用读取『已经写入到大多数节点』的策略，除了要注意MongoDB的版本之外，还应该注意以下两点：</p>
<ul>
<li>启动mongod的时候，添加<code>--enableMajorityReadConcern</code>参数</li>
<li>副本集必须使用wt存储引擎，而且选举协议为<code>protocol version 1</code></li>
</ul>
<h3 id="Write-Concern-数据写策略"><a href="#Write-Concern-数据写策略" class="headerlink" title="Write Concern(数据写策略)"></a>Write Concern(数据写策略)</h3><p>写策略主要讨论的问题是MongoDB写操作的确认等级，写请求确认等级影响了写操作的速度。如果写确认等级比较低，写速度快，随着确认等级的升高，客户端可能要花更多的时间等待MongoDB进行写确认。如果说配置的写确认等级较低，有可能会出现写操作返回成功，但是并没有数据发生改变的情况</p>
<p>所以在生产环境使用MongoDB之前需要先考虑好合适的写操作确认等级</p>
<h2 id="Networking-网络"><a href="#Networking-网络" class="headerlink" title="Networking(网络)"></a>Networking(网络)</h2><h3 id="Use-Trusted-Networking-Environments-使用可信任的网络环境"><a href="#Use-Trusted-Networking-Environments-使用可信任的网络环境" class="headerlink" title="Use Trusted Networking Environments(使用可信任的网络环境)"></a>Use Trusted Networking Environments(使用可信任的网络环境)</h3><p>请在可信任的环境下运行MongoDB，通过网络保护策略保护MongoDB被任何非法的机器，系统，或者是网络访问（一般就是指在内网环境中启动运行MongoDB，只有同一内网的机器才有权限访问MongoDB）。如果必须暴露在网络环境中，MongoDB必须要配合相应的权限系统，监控系统等去保证MongDB不被非法访问。</p>
<blockquote>
<p>默认情况下，MongoDB的权限认证系统不会开启</p>
</blockquote>
<p>关于MongoDB的安全性，还有以下文章参考：</p>
<ul>
<li><a href="https://docs.mongodb.com/manual/administration/security-checklist/" target="_blank" rel="external">Security Checklist</a></li>
<li><a href="https://docs.mongodb.com/manual/core/security-mongodb-configuration/" target="_blank" rel="external">MongoDB Configuration Hardening</a></li>
<li><a href="https://docs.mongodb.com/manual/core/security-network/" target="_blank" rel="external">Hardening Network Infrastructure</a></li>
</ul>
<h3 id="Disable-HTTP-Interface-禁用http接口"><a href="#Disable-HTTP-Interface-禁用http接口" class="headerlink" title="Disable HTTP Interface(禁用http接口)"></a>Disable HTTP Interface(禁用http接口)</h3><p>MongoDB提供了一个http接口，用于检查节点状态，而且也可以用来执行一些脚本。http接口默认关闭，不能在生产环境开启http接口</p>
<h3 id="Manage-Connection-Pool-Sizes-连接池管理"><a href="#Manage-Connection-Pool-Sizes-连接池管理" class="headerlink" title="Manage Connection Pool Sizes(连接池管理)"></a>Manage Connection Pool Sizes(连接池管理)</h3><p>为了避免连接资源过载（常见的can not get resource from the pool），要预估连接池大小，设定一个比较合理的值。通常的经验是，在一开始的时候设定连接池的大小为当前平均数据库请求数量的110-115%，并且需要根据实际情况的改变而进行调整。参考<a href="https://docs.mongodb.com/manual/reference/connection-string/#connection-pool-options" target="_blank" rel="external">数据库连接池相关参数说明</a></p>
<p><code>connPoolStats</code>命令可以用来查询当前数据库连接数</p>
<h2 id="Hardware-Considerations-硬件注意事项"><a href="#Hardware-Considerations-硬件注意事项" class="headerlink" title="Hardware Considerations(硬件注意事项)"></a>Hardware Considerations(硬件注意事项)</h2><p>MongoDB对硬件的要求和限制相对较低</p>
<h3 id="Allocate-Sufficient-RAM-and-CPU-充足的内存和cpu"><a href="#Allocate-Sufficient-RAM-and-CPU-充足的内存和cpu" class="headerlink" title="Allocate Sufficient RAM and CPU(充足的内存和cpu)"></a>Allocate Sufficient RAM and CPU(充足的内存和cpu)</h3><h4 id="MMAPv1-1"><a href="#MMAPv1-1" class="headerlink" title="MMAPv1"></a>MMAPv1</h4><p>由于<code>MMAPv1</code>自身的并发模型，它并不需要很多的CPU内核。当然，如果增加了CPU内核数量，可以提高一部分性能，但是并不会减少单次处理的相应时间，至少需要一个双核物理CPU。</p>
<p>增加内存可以帮助MongoDB减少页交换次数，关于如何查看centos系统缺页信息，请参考<a href="https://github.com/chyyuu/ucore_os_lab/blob/master/related_info/lab2/watch_linux_pagefault.md" target="_blank" rel="external">这里</a></p>
<h4 id="WiredTiger-1"><a href="#WiredTiger-1" class="headerlink" title="WiredTiger"></a>WiredTiger</h4><p>WiredTiger是一个多线程的存储引擎，能充分发挥出多核CPU的优势。当前活跃线程数和CPU数量的比例影响着wt的性能</p>
<ul>
<li>增加线程数量至CPU核数能提高吞吐量</li>
<li>如果活跃线程数量超出CPU数量到达一定成都的时候，吞吐量会下降</li>
</ul>
<p><code>mongostat</code>可以用来查看当前活跃操作数</p>
<p>WiredTiger存储引擎，既使用了WiredTiger内部缓存，也使用了文件系统缓存</p>
<p>MongoDB3.4开始，WiredTiger将会内部缓存将会占用以下（较大的一个）内存空间：</p>
<ul>
<li>50%的内存减去1GB</li>
<li>256MB</li>
</ul>
<p>由于使用了系统缓存，MongoDB实际上会使用掉所有没有被WiredTiger内部缓存和其他应用程序占用的内存空间。文件系统缓存中的数据是被压缩过的</p>
<p>为了调整WiredTiger内部缓存大小，可以通过设定参数<code>storage.wiredTiger.engineConfig.cacheSizeGB</code>或者<code>--wiredTigerCacheSizeGB</code>。避免设置的内部缓存大小大于默认值（个人认为这样处理可能是为了防止内存溢出的问题）</p>
<blockquote>
<p>注意：<code>storage.wiredTiger.engineConfig.cacheSizeGB</code>限制的是WiredTiger内部缓存占用内存大小。因为使用文件系统缓存的原因，操作系统会使用剩余的全部内存空间（所以跑着大业务量的mongod的机器内存使用总会100%）。</p>
</blockquote>
<p>这个设定（WiredTiger内部缓存默认值）的前提是一个机器上只运行一个mongod实例，如果你的机器上运行了多个mongod实例的话，应该把这个配置相对调低。生产环境不推荐一个机器上启动多个mongod进程。</p>
<p>如果是在容器中运行mongod实例（单个容器往往没有权限使用全部内存），这时候需要把<code>storage.wiredTiger.engineConfig.cacheSizeGB</code>的值设的小于容器可使用的内存空间大小</p>
<p>查看WiredTiger内部缓存到底占用了多少内存的方式是，在mongo shell中之行以下命令：<code>db.runCommand( { serverStatus: 1 } ).wiredTiger.cache[&quot;bytes currently in the cache&quot;]</code></p>
<h3 id="Compression-and-Encryption-压缩和加密"><a href="#Compression-and-Encryption-压缩和加密" class="headerlink" title="Compression and Encryption(压缩和加密)"></a>Compression and Encryption(压缩和加密)</h3><p>当开启加密功能的时候，配备AES-NI指令集扩展的CPU的性能表现最好。如果你使用的是企业级mongodb，而且使用了加密存储引擎，请选择配备AES-NI指令集扩展的CPU</p>
<h3 id="Use-Solid-State-Disks-SSDs-使用固态硬盘"><a href="#Use-Solid-State-Disks-SSDs-使用固态硬盘" class="headerlink" title="Use Solid State Disks (SSDs)(使用固态硬盘)"></a>Use Solid State Disks (SSDs)(使用固态硬盘)</h3><p>推荐在生产环境中使用固态硬盘，这样能带来更高的性价比。固态硬盘的随机读写能力非常适合MMMapv1的更新模型。</p>
<p><a href="https://zhidao.baidu.com/question/166368197.html" target="_blank" rel="external">SATA与SSD固态硬盘有什么区别</a></p>
<h3 id="MongoDB-and-NUMA-Hardware-非均匀存储器访问"><a href="#MongoDB-and-NUMA-Hardware-非均匀存储器访问" class="headerlink" title="MongoDB and NUMA Hardware(非均匀存储器访问)"></a>MongoDB and NUMA Hardware(非均匀存储器访问)</h3><p>在一个非均匀内存访问的系统中运行MongoDB可能会带来比较多的问题。包括慢查询和高CPU占用。</p>
<p>关于这部分详细内容，请具体参考<a href="https://docs.mongodb.com/manual/administration/production-notes/#mongodb-and-numa-hardware" target="_blank" rel="external">MongoDB Production Notes</a></p>
<h3 id="Disk-and-Storage-Systems-磁盘和存储系统"><a href="#Disk-and-Storage-Systems-磁盘和存储系统" class="headerlink" title="Disk and Storage Systems(磁盘和存储系统)"></a>Disk and Storage Systems(磁盘和存储系统)</h3><h4 id="swap-交换空间"><a href="#swap-交换空间" class="headerlink" title="swap(交换空间)"></a>swap(交换空间)</h4><p>生产环境中要为的系统分配交换空间。配置交换空间可以避免内存争用问题，防止Linux中的<a href="理解和配置 Linux 下的 OOM Killer">OOM Killer</a>杀掉mongod进程</p>
<p>当使用MMAPv1存储引擎的时候，mongod使用文件映射到内存的方法确保了操作系统不会将MongoDB数据存储在交换空间。在Windows系统上,因为一些限制，使用MMAPv1需要额外的交换空间在，参考<a href="https://docs.mongodb.com/manual/administration/production-notes/#production-windows-pagefile" target="_blank" rel="external">MongoDB on Windows</a></p>
<p>WiredTiger存储引擎在内存不够用的情况下可能会将部分数据存储在交换空间</p>
<h4 id="RAID-磁盘阵列"><a href="#RAID-磁盘阵列" class="headerlink" title="RAID(磁盘阵列)"></a>RAID(磁盘阵列)</h4><p>大部分生产环境中MongoDB运行环境中，磁盘阵列组合方式都是raid-10</p>
<p>raid-5和raid-6组合方式性能不如raid-10</p>
<p>不要在生产环境中使用raid-0，虽然raid-0提供了很好的写性能，但是它也存在一些缺点，例如会降低读性能。尤其是使用亚马DBS volumes</p>
<p>关于raid，可以参考<a href="https://zh.wikipedia.org/wiki/RAID" target="_blank" rel="external">这里</a></p>
<h4 id="Remote-Filesystems-远程文件系统"><a href="#Remote-Filesystems-远程文件系统" class="headerlink" title="Remote Filesystems(远程文件系统)"></a>Remote Filesystems(远程文件系统)</h4><p>总的来说，远程文件系统是不推荐在生产环境使用的，主要是因为性能问题</p>
<p>如果使用MMAPv1存储引擎，不推荐网络文件系统(NFS)，如果数据文件和日志文件都托管在NFS会导致性能问题。如果将数据文件和日志文件放在本地性能将会提高很多</p>
<p>当使用的是WiredTiger存储引擎的时候，如果远程文件系统符合ISO / IEC 9945 - 1:1996，WiredTiger对象就可以远程存储。因为通常情况下远程文件系统都比本地文件系统慢，所以使用远程文件系统会降低MongoDB的性能</p>
<p>如果决定使用NFS，添加以下的NFS选项到<code>/etc/fstab</code>文件：<code>bg</code>, <code>nolock</code>, 和 <code>noatime</code></p>
<h4 id="Separate-Components-onto-Different-Storage-Devices-不同组件使用不同的存储设备"><a href="#Separate-Components-onto-Different-Storage-Devices-不同组件使用不同的存储设备" class="headerlink" title="Separate Components onto Different Storage Devices(不同组件使用不同的存储设备)"></a>Separate Components onto Different Storage Devices(不同组件使用不同的存储设备)</h4><p>为了提高性能，可以根据应用程序的数据读写模式将数据库文件，journal文件，log文件等写到不同的存储设备上。将组件挂载为一个独立的文件系统，然后通过符号链接将对应的存储设备映射过去</p>
<p>如果使用WiredTiger存储引擎，也可以将索引单独存储到不同的存储设备上。、</p>
<blockquote>
<p>注意，使用不同的存储设备将会影响数据库快照备份，因为文件需要被存储到不同的设备和数据卷上</p>
</blockquote>
<h3 id="Scheduling-调度"><a href="#Scheduling-调度" class="headerlink" title="Scheduling(调度)"></a>Scheduling(调度)</h3><h4 id="Scheduling-for-Virtual-or-Cloud-Hosted-Devices-虚拟设备或云托管设备的调度"><a href="#Scheduling-for-Virtual-or-Cloud-Hosted-Devices-虚拟设备或云托管设备的调度" class="headerlink" title="Scheduling for Virtual or Cloud Hosted Devices(虚拟设备或云托管设备的调度)"></a>Scheduling for Virtual or Cloud Hosted Devices(虚拟设备或云托管设备的调度)</h4><p>如果使用虚拟机或者是云服务运行MongoDB，操作系统应该使用等待调度方式以获得最佳性能。等待调度方式允许操作系统I/O调度遵从底层虚拟机监控程序。</p>
<h4 id="Scheduling-for-Physical-Servers-物理机调度"><a href="#Scheduling-for-Physical-Servers-物理机调度" class="headerlink" title="Scheduling for Physical Servers(物理机调度)"></a>Scheduling for Physical Servers(物理机调度)</h4><p>如果使用物理机运行MongoDB，那么操作系统应该使用<code>deadline scheduler</code>的调度方式。<code>deadline scheduler</code>记录每个请求的最大延迟时间并且能够为磁盘敏感型数据库应用维持一个最合适的磁盘吞吐率</p>
<h2 id="Architecture-架构"><a href="#Architecture-架构" class="headerlink" title="Architecture(架构)"></a>Architecture(架构)</h2><h3 id="Replica-Sets-副本集"><a href="#Replica-Sets-副本集" class="headerlink" title="Replica Sets(副本集)"></a><a href="https://docs.mongodb.com/manual/administration/production-notes/#replica-sets" target="_blank" rel="external">Replica Sets(副本集)</a></h3><h3 id="Sharded-Clusters-分片集群"><a href="#Sharded-Clusters-分片集群" class="headerlink" title="Sharded Clusters 分片集群"></a><a href="https://docs.mongodb.com/manual/administration/production-notes/#sharded-clusters" target="_blank" rel="external">Sharded Clusters 分片集群</a></h3><h2 id="Compression-压缩"><a href="#Compression-压缩" class="headerlink" title="Compression(压缩)"></a>Compression(压缩)</h2><p>WiredTiger可以使用<a href="https://docs.mongodb.com/manual/reference/glossary/#term-snappy" target="_blank" rel="external">snappy</a>和<a href="https://docs.mongodb.com/manual/reference/glossary/#term-zlib" target="_blank" rel="external">zlib</a>两种方式压缩数据。snappy拥有较低的压缩比，但是性能损耗小；zlib能获得更高的压缩比，但是性能损耗多</p>
<p>默认情况下，WiredTiger使用snappy作为默认的压缩库，如果想改变默认的压缩设置，查看<a href="https://docs.mongodb.com/manual/reference/configuration-options/#storage.wiredTiger.collectionConfig.blockCompressor" target="_blank" rel="external">storage.wiredTiger.collectionConfig.blockCompressor</a></p>
<h2 id="Platform-Specific-Considerations-不同平台注意事项"><a href="#Platform-Specific-Considerations-不同平台注意事项" class="headerlink" title="Platform Specific Considerations(不同平台注意事项)"></a>Platform Specific Considerations(不同平台注意事项)</h2><blockquote>
<p>MongoDB会使用系统安装的glibc，并且要求glibc的版本至少在glibc-2.12-1.2.el6，否则会出现一些已知的bug，为了避免问题最好让glibc版本高于2.13</p>
</blockquote>
<h3 id="MongoDB-on-Linux-在linux上使用MongoDB"><a href="#MongoDB-on-Linux-在linux上使用MongoDB" class="headerlink" title="MongoDB on Linux(在linux上使用MongoDB)"></a>MongoDB on Linux(在linux上使用MongoDB)</h3><h4 id="Kernel-and-File-Systems-内核和文件系统"><a href="#Kernel-and-File-Systems-内核和文件系统" class="headerlink" title="Kernel and File Systems(内核和文件系统)"></a>Kernel and File Systems(内核和文件系统)</h4><p><strong>如果在Linux上使用MongoDB，那么Linux内核版本必须高于2.6.36，而且要使用XFS或者是EXT4文件系统。如果可能的话，尽量使用XFS，因为总体上MongoDB在XFS文件系统上运行地更好</strong></p>
<p><strong>当使用WiredTiger存储引擎的时候，强烈推荐使用XFS文件系统，因为这样能够避免因为使用EXT4文件系统导致的性能问题</strong></p>
<p>当使用MMapv1存储引擎的时候，MongoDB会预先创建数据库文件占用磁盘空间，虽然这时候还没有真的存储数据，而且通常创建的文件都比较大，基于这点考虑，同样推荐使用XFS和EXT4文件系统。如果可能的话，尽量使用XFS</p>
<p>注意：</p>
<ul>
<li>通常情况下，如果使用XFS文件系统，Linux内核版本至低是2.6.25</li>
<li>如果使用EXT4文件系统，Linux内核版本最低是2.6.28</li>
<li>如果使用Red Hat Enterprise或者是CentOS，内核版本最低为2.6.18-194</li>
</ul>
<h4 id="fsync-on-Directories"><a href="#fsync-on-Directories" class="headerlink" title="fsync() on Directories"></a>fsync() on Directories</h4><blockquote>
<p>MongoDB要求文件系统支持fsync()方法，HGFS和Virtual Box’s shared folders都不支持改方法</p>
</blockquote>
<h4 id="Recommended-Configuration-推荐配置"><a href="#Recommended-Configuration-推荐配置" class="headerlink" title="Recommended Configuration(推荐配置)"></a>Recommended Configuration(推荐配置)</h4><p><em>对于所有的MongoDB部署环境：</em></p>
<ul>
<li>主机必须使用Network Time Protocol (NTP)来同步时钟，这对于分片集群来说非常重要</li>
</ul>
<p>关于WiredTiger和MMAPv1存储引擎，有以下推荐配置：</p>
<ul>
<li>关掉存储数据文件的volumn的atime</li>
<li>设定文件描述符限制<code>-n</code>和用户进程可占用文件描述符数量限制(ulimit)<code>-u</code>高于20000，相关内容参考<a href="https://docs.mongodb.com/manual/reference/ulimit/" target="_blank" rel="external">这里</a>。ulimit过低将可能会导致MongoDB在业务繁忙的时候产生错误，进而甚至导致数据库连接失败，服务不可用等严重情况</li>
<li>关闭透明大页，MongoDB使用普通虚拟内存页性能表现更好</li>
<li>在BIOS中关闭NUMA</li>
<li>禁用SELinux，如果可能的话。如果已经在Red Hat操作系统中使用了SELinux，必须做好相应配置，参考<a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-on-red-hat/#install-rhel-configure-selinux" target="_blank" rel="external">Configure SELinux for MongoDB</a>和<a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/#install-enterprise-rhel-configure-selinux" target="_blank" rel="external">Configure SELinux for MongoDB Enterprise</a></li>
</ul>
<blockquote>
<p>如果使用SELinux，任何需要使用server-side javascript的MongoDB操作语句将会导致segfault errors。<a href="https://docs.mongodb.com/manual/core/server-side-javascript/#disable-server-side-js" target="_blank" rel="external">Disable Server-Side Execution of JavaScript</a>介绍了如何禁止执行server-side javascript</p>
</blockquote>
<p>补充说明：</p>
<ul>
<li>atime<br>参考<a href="http://jianjian.blog.51cto.com/35031/103231" target="_blank" rel="external">这篇文章</a>，因为数据库文件可能频繁被修改，如果关闭atime，这样避免文件改动带来的atime的修改影响部分性能</li>
<li>ulimit<br>参考<a href="http://blog.csdn.net/cywosp/article/details/38965239" target="_blank" rel="external">这篇文章</a>，一般最大打开文件数会是系统内存的10%（以KB来计算）（称之为系统级限制），查看系统级别的最大打开文件数可以使用<code>sysctl -a | grep fs.file-max</code>命令查看。与此同时，内核为了不让某一个进程消耗掉所有的文件资源，其也会对单个进程最大打开文件数做默认值处理（称之为用户级限制），默认值一般是1024，使用<code>ulimit -n</code>命令可以查看。在Web服务器中，通过更改系统默认值文件描述符的最大值来优化服务器是最常见的方式之一，具体优化方式请查看<a href="http://blog.csdn.net/kumu_linux/article/details/7877770。" target="_blank" rel="external">http://blog.csdn.net/kumu_linux/article/details/7877770。</a></li>
<li>关于<a href="http://www.cnblogs.com/kerrycode/p/4670931.html" target="_blank" rel="external">Transparent Huge Pages(透明大页)</a></li>
<li><a href="https://baike.baidu.com/item/NUMA" target="_blank" rel="external">numa</a></li>
</ul>
<p><em>针对使用WiredTiger存储引擎的建议：</em></p>
<ul>
<li>不管使用什么类型的存储介质（机械硬盘，ssd），都要将linux系统readahead（文件预读）设置为0。设定更高等级的文件预读参数有利于连续的io操作，但是MongoDB的磁盘操作通常情况下都是随机的，调高文件预读等级只能带来有限的好处，而且会影响MongoDB本身的性能。因此，将readahead设置为0在大部分的工作场景中能让MonoDB获得最佳性能。</li>
</ul>
<p><em>针对使用MMAPv1存储引擎的建议：</em></p>
<ul>
<li>保证存储数据库文件的块设备的readahead是合适的。针对硬盘的随机读写操作类型，可以设定较低的readahead为32（16KB）。对于标准块设备，<code>sudo blockdev --report</code>可以获取当前readahead值，<code>sudo blockdev --setra &lt;value&gt; &lt;device&gt;</code>可以用于制定设备的值</li>
</ul>
<blockquote>
<p>补充说明：<br>readahead（文件预读）: Linux的文件预读readahead，指Linux系统内核将指定文件的某区域预读进页缓存起来，便于接下来对该区域进行读取时，不会因缺页（page fault）而阻塞。因为从内存读取比从磁盘读取要快很多。预读可以有效的减少磁盘的寻道次数和应用程序的I/O等待时间，是改进磁盘读I/O性能的重要优化手段之一。</p>
</blockquote>
<h4 id="MongoDB-and-TLS-SSL-libraries"><a href="#MongoDB-and-TLS-SSL-libraries" class="headerlink" title="MongoDB and TLS/SSL libraries"></a>MongoDB and TLS/SSL libraries</h4><p>在Linux系统中可能会看到以下错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&lt;path to SSL libs&gt;/libssl.so.&lt;version&gt;: no version information available (required by /usr/bin/mongod)</div><div class="line">&lt;path to SSL libs&gt;/libcrypto.so.&lt;version&gt;: no version information available (required by /usr/bin/mongod)</div></pre></td></tr></table></figure></p>
<p>这个警告说明了系统的TLS/SSL库和编译MongoDB使用的不一致，通常情况下并不需要关注这个，但仍然可以使用以下命令来查看MongoDB需要的TLS/SSL库版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">objdump -T &lt;path to mongod&gt;/mongod | grep &quot; SSL_&quot;</div><div class="line">objdump -T &lt;path to mongod&gt;/mongod | grep &quot; CRYPTO_&quot;</div></pre></td></tr></table></figure></p>
<p>上述命令将返回以下结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">0000000000000000      DF *UND*       0000000000000000  libssl.so.10 SSL_write</div><div class="line">0000000000000000      DF *UND*       0000000000000000  OPENSSL_1.0.0 SSL_write</div></pre></td></tr></table></figure></p>
<p>接下来检测下系统中的TLS/SSL库的版本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">objdump -T &lt;path to TLS/SSL libs&gt;/libssl.so.1*</div><div class="line">objdump -T &lt;path to TLS/SSL libs&gt;/libcrypto.so.1*</div></pre></td></tr></table></figure></p>
<p>上述方法，既不准确，也不完善，仅供参考</p>
<h3 id="MongoDB-on-Windows"><a href="#MongoDB-on-Windows" class="headerlink" title="MongoDB on Windows"></a>MongoDB on Windows</h3><p>感兴趣的可以参考<a href="https://docs.mongodb.com/manual/administration/production-notes/#mongodb-on-windows" target="_blank" rel="external">这里</a></p>
<h3 id="MongoDB-on-Virtual-Environments"><a href="#MongoDB-on-Virtual-Environments" class="headerlink" title="MongoDB on Virtual Environments"></a>MongoDB on Virtual Environments</h3><h4 id="EC2"><a href="#EC2" class="headerlink" title="EC2"></a>EC2</h4><p>MongoDB兼容EC2，<a href="https://www.mongodb.com/cloud/cloud-manager/?jmp=docs&amp;_ga=2.133439246.1051480522.1501766469-1069453493.1477385716" target="_blank" rel="external">MongoDB Cloud Manager</a>可以部署在AWS上，然后可以使用MongoDB Cloud Manager在EC2上部署mongod实例，详情参考<a href="Configure AWS Integration">Configure AWS Integration</a></p>
<h4 id="Azure"><a href="#Azure" class="headerlink" title="Azure"></a><a href="https://docs.mongodb.com/manual/administration/production-notes/#azure" target="_blank" rel="external">Azure</a></h4><h4 id="VMWare"><a href="#VMWare" class="headerlink" title="VMWare"></a>VMWare</h4><p>MongoDB兼容VMWare</p>
<p>VMWare支持内存过载，所以可以给虚拟机分配超出物理机实际内存大小的内存值。当内存过载时，管理程序会给虚拟机重新分配内存。VMWare balloon driver (vmmemctl)会自动回收它认为最没有价值的内存，balloon driver运行在虚拟机中，当balloon driver扩大时，会导致虚拟机回收应用的内存，这个会影响MongoDB的内存管理，影响MongoDB的内存</p>
<p>可以通过关闭balloon driver和VMWare的内存过载功能来避免上述问题。但是，关闭balloon driver会导致管理程序使用交换分区，因为没有其他的能够用来执行内存回收的机制。从swap读写数据要比从内存慢得多，这也会影响性能。因此关闭balloon driver和VMWare的内存过载功能不是最佳方案，最佳方案是给运行MongoDB的虚拟机分配全部内存，这样就能保证MongoDB不会被影响</p>
<p>使用VMWare的时候，确保每个物理CPU虚拟出来的CPU数量不超过2</p>
<p>使用vMotion关闭VMWare的（动态迁移）。虚拟机的动态迁移会导致性能问题，而且会影响MongoDB副本集和分片集群机制</p>
<p>可以克隆一个正在运行着MongoDB的虚拟机，也就是说可以使用这种方式快速的把一个MongoDB单点做成一个副本集。如果克隆一个开启了journaling的MongoDB的VM，直接克隆就能MongoDB就能启动。如果MongoDB没有开启，先关闭MongoDB，然后克隆VM，然后重启MongoDB</p>
<h4 id="KVM"><a href="#KVM" class="headerlink" title="KVM"></a>KVM</h4><p>MongoDB兼容KVM</p>
<p>KVM支持内存过载，所以可以给虚拟机分配超出物理机实际内存大小的内存值。当内存过载时，管理程序会给虚拟机重新分配内存。KVM balloon driver (vmmemctl)会自动回收它认为最没有价值的内存，balloon driver运行在虚拟机中，当balloon driver扩大时，会导致虚拟机回收应用的内存，这个会影响MongoDB的内存管理，影响MongoDB的内存</p>
<p>可以通过关闭balloon driver和KVM的内存过载功能来避免上述问题。但是，关闭balloon driver会导致管理程序使用交换分区，因为没有其他的能够用来执行内存回收的机制。从swap读写数据要比从内存慢得多，这也会影响性能。因此关闭balloon driver和KVM的内存过载功能不是最佳方案，最佳方案是给运行MongoDB的虚拟机分配全部内存，这样就能保证MongoDB不会被影响</p>
<p>使用KVM的时候，确保每个物理CPU虚拟出来的CPU数量不超过2</p>
<h2 id="性能监控"><a href="#性能监控" class="headerlink" title="性能监控"></a>性能监控</h2><h3 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h3><p>在Linux系统中，可以使用iostat去检查数据库是否存在磁盘io瓶颈</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iostat -xmt 1</div></pre></td></tr></table></figure>
<p>iostat关键字段：</p>
<ul>
<li>%util: 这个字段价值最大，它代表了当前指定时间磁盘使用百分比</li>
<li>avgrq-sz: 平均请求大小，这个数值越小表示有越多的random IO</li>
</ul>
<h3 id="bwm-ng"><a href="#bwm-ng" class="headerlink" title="bwm-ng"></a>bwm-ng</h3><p>这是个监控网络状态的命令行工具，可以用来确认是否存在网络瓶颈</p>
<h2 id="Backups"><a href="#Backups" class="headerlink" title="Backups"></a>Backups</h2><p>数据备份请参考<a href="https://docs.mongodb.com/manual/core/backups/" target="_blank" rel="external">这里</a></p>
<h2 id="其他参考链接"><a href="#其他参考链接" class="headerlink" title="其他参考链接"></a>其他参考链接</h2><ul>
<li><a href="Blog Post: Capacity Planning and Hardware Provisioning for MongoDB In Ten Minutes">Blog Post: Capacity Planning and Hardware Provisioning for MongoDB In Ten Minutes</a></li>
<li><a href="http://www.mongodb.com/lp/white-paper/multi-dc?jmp=docs&amp;_ga=2.133419918.1051480522.1501766469-1069453493.1477385716" target="_blank" rel="external">Whitepaper: MongoDB Multi-Data Center Deployments</a></li>
<li><a href="https://www.mongodb.com/lp/white-paper/mongodb-security-architecture?jmp=docs&amp;_ga=2.133419918.1051480522.1501766469-1069453493.1477385716" target="_blank" rel="external">Whitepaper: Security Architecture</a></li>
<li><a href="https://www.mongodb.com/lp/whitepaper/architecture-guide?jmp=docs&amp;_ga=2.133419918.1051480522.1501766469-1069453493.1477385716" target="_blank" rel="external">Whitepaper: MongoDB Architecture Guide</a></li>
<li><a href="http://www.mongodb.com/presentations/webinar-mongodb-administration-101?jmp=docs&amp;_ga=2.133419918.1051480522.1501766469-1069453493.1477385716" target="_blank" rel="external">Presentation: MongoDB Administration 101</a></li>
<li><a href="https://www.mongodb.com/products/consulting?jmp=docs&amp;_ga=2.133419918.1051480522.1501766469-1069453493.1477385716#s_product_readiness" target="_blank" rel="external">MongoDB Production Readiness Consulting Package</a></li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://docs.mongodb.com/manual/administration/production-notes/" target="_blank" rel="external">MongoDB Production Notes</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;MongoDB二进制文件&quot;&gt;&lt;a href=&quot;#MongoDB二进制文件&quot; class=&quot;headerlink&quot; title=&quot;MongoDB二进制文件&quot;&gt;&lt;/a&gt;MongoDB二进制文件&lt;/h2&gt;&lt;h3 id=&quot;支持的运行平台&quot;&gt;&lt;a href=&quot;#支持的运行平台&quot; class=&quot;headerlink&quot; title=&quot;支持的运行平台&quot;&gt;&lt;/a&gt;支持的运行平台&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/administration/production-notes/#x86-64&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;x86_64&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/administration/production-notes/#arm64&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ARM64&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/administration/production-notes/#ppc64le-mongodb-enterprise-edition&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;PPC64LE (MongoDB Enterprise Edition)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/administration/production-notes/#s390x-mongodb-enterprise-edition&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;s390x (MongoDB Enterprise Edition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="mongodb" scheme="http://cocacola183.github.io/categories/mongodb/"/>
    
    
      <category term="mongodb" scheme="http://cocacola183.github.io/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>mongodb wt数据文件损坏解决方案</title>
    <link href="http://cocacola183.github.io/2017/07/08/mongo/mongodb-wt%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>http://cocacola183.github.io/2017/07/08/mongo/mongodb-wt数据文件损坏解决方案/</id>
    <published>2017-07-08T02:34:04.000Z</published>
    <updated>2017-07-10T03:34:05.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.alexbevi.com/blog/2016/02/10/recovering-a-wiredtiger-collection-from-a-corrupt-mongodb-installation/" target="_blank" rel="external">原文链接</a><br><a href="http://dev.guanghe.tv/2016/06/06/recovering-a-wiredtiger-collection-from-a-corrupt-wt-file/" target="_blank" rel="external">译文链接</a>，我看的这篇，因为没有给出来原文链接，所以刚开始没找到原文</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><blockquote>
<p>数据文件是wt文件，而且是通过<code>snappy</code>方式压缩的，如果不是通过<code>snappy</code>方式，也可以参考下这个方式，不过执行命令可能有所不同 </p>
</blockquote>
<p>这个解决方案非常适合这样的场景：服务器意外故障（例如断电），突然停机，导致mongodb数据文件损坏，进而导致了<code>mongod</code>进程无法启动</p>
<a id="more"></a>
<p>但是我却是遇到了这样的问题：服务器由于磁盘空间占用达到100%导致<code>mongod</code>进程挂掉，由于磁盘100%，无法再启动mongo进程，所以工作人员直接删掉了部分的wt文件，释放部分磁盘空间，然后再次启动mongo的时候，发现无法启动了。。。</p>
<p>无法启动的原因是mongo启动的时候会做一次检测，检查mongodb的数据文件和某个地方存储的信息是否一致的（具体这个位置我们暂时还不清楚），如果不一致，将会无法启动mongo进程。进程无法启动导致了很多严重的问题，好在这个数据库记录的都是一些非业务信息，数据的查询更新操作也不算太多，为了让集群快速可用，我们直接更改了一个空的数据目录，启动<code>mongod</code>进程，让集群先可用</p>
<p>然后问题来了，原来的数据要怎么恢复呢？于是我们就有了从wt文件中抽取出数据的需求，所以就有了以下过程</p>
<h2 id="恢复过程"><a href="#恢复过程" class="headerlink" title="恢复过程"></a>恢复过程</h2><h3 id="准备工具"><a href="#准备工具" class="headerlink" title="准备工具"></a>准备工具</h3><p><a href="http://source.wiredtiger.com/" target="_blank" rel="external">最新下载页面</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">yum install -y snappy</div><div class="line">wget http://source.wiredtiger.com/releases/wiredtiger-2.9.3.tar.bz2</div><div class="line"><span class="meta">#</span><span class="bash"> 解压，进入目录</span></div><div class="line">./configure --enable-snappy</div></pre></td></tr></table></figure>
<h3 id="准备恢复目录mongo-bak"><a href="#准备恢复目录mongo-bak" class="headerlink" title="准备恢复目录mongo-bak"></a>准备恢复目录mongo-bak</h3><p>目录包含以下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">collection********.wt</div><div class="line">_mdb_catalog.wt</div><div class="line">sizeStorer.wt</div><div class="line">storage.bson</div><div class="line">WiredTiger</div><div class="line">WiredTiger.basecfg</div><div class="line">WiredTiger.lock</div><div class="line">WiredTiger.turtle</div><div class="line">WiredTiger.wt</div></pre></td></tr></table></figure></p>
<h3 id="数据文件修复（我没做这一步处理因为没有必要）"><a href="#数据文件修复（我没做这一步处理因为没有必要）" class="headerlink" title="数据文件修复（我没做这一步处理因为没有必要）"></a>数据文件修复（我没做这一步处理因为没有必要）</h3><p>打捞出可以修复的部分</p>
<blockquote>
<p>注意仍在wt下载目录下执行</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./wt -v -h ../mongo-bak -C "extensions=[./ext/compressors/snappy/.libs/libwiredtiger_snappy.so]" -R salvage collection******.wt</div></pre></td></tr></table></figure>
<h3 id="数据格式调整"><a href="#数据格式调整" class="headerlink" title="数据格式调整"></a>数据格式调整</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./wt -v -h ../mongo-bak -C "extensions=[./ext/compressors/snappy/.libs/libwiredtiger_snappy.so]" -R dump -f ../collection.dump collection******</div></pre></td></tr></table></figure>
<blockquote>
<p>注意，这个命令的最后一个参数是不带<code>.wt</code>的</p>
</blockquote>
<p>这样就把刚才修复的数据写到<code>collection.dump</code>中了</p>
<h3 id="在目标mongodb中创建一个集合（数据将会被恢复到这个mongodb中）"><a href="#在目标mongodb中创建一个集合（数据将会被恢复到这个mongodb中）" class="headerlink" title="在目标mongodb中创建一个集合（数据将会被恢复到这个mongodb中）"></a>在目标mongodb中创建一个集合（数据将会被恢复到这个mongodb中）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mongo</div><div class="line"><span class="meta">&gt;</span><span class="bash"> use Recovery</span></div><div class="line"><span class="meta">&gt;</span><span class="bash"> db.brokedCollection.insert(&#123;<span class="built_in">test</span>: 1&#125;)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash"> db.brokedCollection.remove(&#123;&#125;)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash"> db.brokedCollection.stats()</span></div></pre></td></tr></table></figure>
<p>创建完成之后，就能看到刚刚新建的wt文件了，假设记为<code>xxx.wt</code></p>
<h3 id="将collection-dump的数据写入xxx-wt"><a href="#将collection-dump的数据写入xxx-wt" class="headerlink" title="将collection.dump的数据写入xxx.wt"></a>将<code>collection.dump</code>的数据写入<code>xxx.wt</code></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./wt -v -h ../tmp-mongo -C "extensions=[./ext/compressors/snappy/.libs/libwiredtiger_snappy.so]" -R load -f ../collection.dump -r xxx</div></pre></td></tr></table></figure>
<blockquote>
<p>注意，这里最后一个参数也是不带wt的。另外执行这一步的时候，必须要先关闭掉mongo进程，否则会提示wt文件被占用，无法写入数据</p>
</blockquote>
<h3 id="查看已经被恢复的数据"><a href="#查看已经被恢复的数据" class="headerlink" title="查看已经被恢复的数据"></a>查看已经被恢复的数据</h3><blockquote>
<p>将mongo进程启动之后，建议使用3.2的mongo客户端链接</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mongo</div><div class="line"><span class="meta">&gt;</span><span class="bash"> show dbs</span></div><div class="line"><span class="meta">&gt;</span><span class="bash"> use Recovery</span></div><div class="line"><span class="meta">&gt;</span><span class="bash"> show collections</span></div><div class="line"><span class="meta">&gt;</span><span class="bash"> db.brokedCollection.count()</span></div></pre></td></tr></table></figure>
<blockquote>
<p><code>count</code>是无法查到数据的，还是需要find</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;</span><span class="bash"> db.brokedCollection.find(&#123;&#125;, &#123;_id: 1&#125;)</span></div></pre></td></tr></table></figure>
<h3 id="将数据dump出来，然后重新写进去"><a href="#将数据dump出来，然后重新写进去" class="headerlink" title="将数据dump出来，然后重新写进去"></a>将数据dump出来，然后重新写进去</h3><p><code>mongodump</code></p>
<p><code>mongorestore</code></p>
<blockquote>
<p>注意，这里的<code>mongodump</code>和<code>mongorestore</code>都要使用3.2版本的</p>
</blockquote>
<p>数据经过导入导出之后就可以<code>count</code>出来了</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>以上恢复过程是针对数据库文件被直接删掉的情况。假如说当前数据库启动无误，这时候一个误删，删掉了数据库文件应该如何处理呢？</p>
<p><a href="https://blogs.gnome.org/raywang/2007/11/30/%E4%BD%BF%E7%94%A8lsof%E6%81%A2%E5%A4%8D%E8%AF%AF%E5%88%A0%E7%9A%84%E6%96%87%E4%BB%B6-%E8%BD%AC/" target="_blank" rel="external">使用lsof恢复误删的文件</a><br>这边文章写的清楚如何进行文件恢复</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.alexbevi.com/blog/2016/02/10/recovering-a-wiredtiger-collection-from-a-corrupt-mongodb-installation/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;原文链接&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://dev.guanghe.tv/2016/06/06/recovering-a-wiredtiger-collection-from-a-corrupt-wt-file/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;译文链接&lt;/a&gt;，我看的这篇，因为没有给出来原文链接，所以刚开始没找到原文&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;数据文件是wt文件，而且是通过&lt;code&gt;snappy&lt;/code&gt;方式压缩的，如果不是通过&lt;code&gt;snappy&lt;/code&gt;方式，也可以参考下这个方式，不过执行命令可能有所不同 &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个解决方案非常适合这样的场景：服务器意外故障（例如断电），突然停机，导致mongodb数据文件损坏，进而导致了&lt;code&gt;mongod&lt;/code&gt;进程无法启动&lt;/p&gt;
    
    </summary>
    
      <category term="mongodb" scheme="http://cocacola183.github.io/categories/mongodb/"/>
    
    
      <category term="mongodb" scheme="http://cocacola183.github.io/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>天云山·北京平谷</title>
    <link href="http://cocacola183.github.io/2017/07/02/travel/%E5%A4%A9%E4%BA%91%E5%B1%B1-%E5%8C%97%E4%BA%AC%C2%B7%E5%B9%B3%E8%B0%B7/"/>
    <id>http://cocacola183.github.io/2017/07/02/travel/天云山-北京·平谷/</id>
    <published>2017-07-02T06:00:00.000Z</published>
    <updated>2018-10-28T14:26:34.368Z</updated>
    
    <content type="html"><![CDATA[<h2 id="参考行程"><a href="#参考行程" class="headerlink" title="参考行程"></a>参考行程</h2><h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>如果和我有一样有以下相同出游前提</p>
<ul>
<li>想站在玻璃制作的观景台上感受下直面万丈深渊的刺激</li>
<li>想爬山</li>
<li>人在北京</li>
<li>想利用周末出游</li>
</ul>
<p>那么这个行程可能有一定的参考价值</p>
<a id="more"></a>
<h3 id="重要说明"><a href="#重要说明" class="headerlink" title="重要说明"></a>重要说明</h3><p>从<a href="http://www.pgtys.com/index.htm" target="_blank" rel="external">天云山旅游风景区官网</a>上看，玻璃栈道目前处于维修状态，而且官网上的旅游路线图已经非常老了，没有任何参考价值，我们沿途走的路线官网上都没有相关信息，玻璃观景台应该是个新加进去的项目。官网上的信息提示玻璃栈道正处在维护当中，所以决定去玩之前看下官网是非常有必要的</p>
<h3 id="出游行程"><a href="#出游行程" class="headerlink" title="出游行程"></a>出游行程</h3><h4 id="大致流程"><a href="#大致流程" class="headerlink" title="大致流程"></a>大致流程</h4><p>2017年7月1日，周六，早上六点半起床（已经非常晚了），七点出发，坐地铁换乘到15号线，坐到终点站俸伯。我们有19站地铁的行程，大约一个小时也就是八点左右到达。朋友有车，从俸伯出发，开车往景点出发，大约又需要一个半小时的行程，才到达经典。新手新车上路，老司机可能快很多。也就是<code>九点半</code>左右开始爬山，大约到了<code>下午三点</code>刚刚好坐缆车到达山底。作为亚健康久坐党，我们的游玩时间应该可以作为充足游玩时间参考。</p>
<h4 id="游玩路线"><a href="#游玩路线" class="headerlink" title="游玩路线"></a>游玩路线</h4><p>我们选择的路线是去玻璃观景台桥的路线，这个路线没办法看到玻璃栈道，玻璃桥，摆渡车。不过玻璃观景台也是非常壮观的。很刺激。虽然带了个入门级的单反，但是没有拍下当时的景点路线图，回来找行程路线发现已经找不到了。总之，去这个地方玩最主要的内容其实就是爬山，如果不愿意爬山的话，建议还是不要来玩了，只是看玻璃栈道，意义并不太大。</p>
<h3 id="出行消费（双人）"><a href="#出行消费（双人）" class="headerlink" title="出行消费（双人）"></a>出行消费（双人）</h3><p>景区门票：78元/人  学生票39元<br>索道价格：单程100元/人<br>玻璃观景台门票： 40元/人 </p>
<h3 id="游玩建议-重要"><a href="#游玩建议-重要" class="headerlink" title="游玩建议(重要)"></a>游玩建议(重要)</h3><ul>
<li>一定自己带好水，半山腰有卖水的，山顶有卖水的，半山腰和山顶之间没有卖水的，半山腰的水，我们没有买，山顶的水10元一瓶，只有常温矿泉水，而且没有冰镇</li>
<li>做好防晒，接近山顶的时候，会有阳光暴晒</li>
<li>还有些其他的登山注意事项这里就不提啦，总之出来玩还是要多准备</li>
<li>景点非常偏僻，建议自驾开车去，周末的车不算太多（我们去的时候还可以），可以不用为怎么回去而担心。如果必须要使用公共交通工具，最好提前规划好路线</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>有山有水，还有点称得上惊险刺激的玩意儿，价格也不算太贵，总的来说还是值得一去的好地方，如果不愿意爬上千万别去。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;参考行程&quot;&gt;&lt;a href=&quot;#参考行程&quot; class=&quot;headerlink&quot; title=&quot;参考行程&quot;&gt;&lt;/a&gt;参考行程&lt;/h2&gt;&lt;h3 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h3&gt;&lt;p&gt;如果和我有一样有以下相同出游前提&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想站在玻璃制作的观景台上感受下直面万丈深渊的刺激&lt;/li&gt;
&lt;li&gt;想爬山&lt;/li&gt;
&lt;li&gt;人在北京&lt;/li&gt;
&lt;li&gt;想利用周末出游&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么这个行程可能有一定的参考价值&lt;/p&gt;
    
    </summary>
    
      <category term="travel" scheme="http://cocacola183.github.io/categories/travel/"/>
    
    
      <category term="travel" scheme="http://cocacola183.github.io/tags/travel/"/>
    
  </entry>
  
  <entry>
    <title>mongodb两段提交</title>
    <link href="http://cocacola183.github.io/2017/06/03/mongo/mongodb%E4%B8%A4%E6%AE%B5%E6%8F%90%E4%BA%A4/"/>
    <id>http://cocacola183.github.io/2017/06/03/mongo/mongodb两段提交/</id>
    <published>2017-06-02T23:57:25.000Z</published>
    <updated>2017-07-08T02:34:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p>mongodb所有的针对单个文档的操作都具有原子性，但是当一个操作涉及多个文档更新的时候，是非原子性的。但在生产环境中，是存在多文档更新的需求的，一般情况下，包含以下两个方面：</p>
<ul>
<li>原子性：如果任何一个操作失败，所有已经进行的操作全部回滚，并且中断接下来的所有操作</li>
<li>一致性：如果操作执行过程遭遇中断，例如断电，数据库要有能力保持数据一致性</li>
</ul>
<p>为了解决多文档更新事务性问题，可以使用两段提交的方式处理。两段提交可以保证数据是一致的，而且可以保证遇到错误之后可以恢复，但是在执行期间，文档本身处于待定状态</p>
<blockquote>
<p>注意：因为mongodb只有单文档操作具有事务性，两段提交只能提供类似原子操作的语义，而不是提供完善的事务机制</p>
</blockquote>
<a id="more"></a>
<h2 id="应用示例"><a href="#应用示例" class="headerlink" title="应用示例"></a>应用示例</h2><h3 id="场景："><a href="#场景：" class="headerlink" title="场景："></a>场景：</h3><p>银行账户A转账给银行账户B</p>
<p>该场景会使用两个集合：</p>
<ul>
<li>accounts  记录用户信息</li>
<li>transactions  记录转账事务状态</li>
</ul>
<h3 id="初始化账户信息"><a href="#初始化账户信息" class="headerlink" title="初始化账户信息"></a>初始化账户信息</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">db.accounts.insert(</div><div class="line">   [</div><div class="line">     &#123; <span class="attr">_id</span>: <span class="string">"A"</span>, <span class="attr">balance</span>: <span class="number">1000</span>, <span class="attr">pendingTransactions</span>: [] &#125;,</div><div class="line">     &#123; <span class="attr">_id</span>: <span class="string">"B"</span>, <span class="attr">balance</span>: <span class="number">1000</span>, <span class="attr">pendingTransactions</span>: [] &#125;</div><div class="line">   ]</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="初始化转账记录表"><a href="#初始化转账记录表" class="headerlink" title="初始化转账记录表"></a>初始化转账记录表</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">db.transactions.insert(</div><div class="line">    &#123; <span class="attr">_id</span>: <span class="number">1</span>, <span class="attr">source</span>: <span class="string">"A"</span>, <span class="attr">destination</span>: <span class="string">"B"</span>, <span class="attr">value</span>: <span class="number">100</span>, <span class="attr">state</span>: <span class="string">"initial"</span>, <span class="attr">lastModified</span>: <span class="keyword">new</span> <span class="built_in">Date</span>() &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="查找转账事务"><a href="#查找转账事务" class="headerlink" title="查找转账事务"></a>查找转账事务</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> t = db.transactions.findOne( &#123; <span class="attr">state</span>: <span class="string">"initial"</span> &#125; )</div></pre></td></tr></table></figure>
<h3 id="将转账事务状态由initial改为pending"><a href="#将转账事务状态由initial改为pending" class="headerlink" title="将转账事务状态由initial改为pending"></a>将转账事务状态由initial改为pending</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(</div><div class="line">    &#123; <span class="attr">_id</span>: t._id, <span class="attr">state</span>: <span class="string">"initial"</span> &#125;,</div><div class="line">    &#123;</div><div class="line">      <span class="attr">$set</span>: &#123; <span class="attr">state</span>: <span class="string">"pending"</span> &#125;,</div><div class="line">      <span class="attr">$currentDate</span>: &#123; <span class="attr">lastModified</span>: <span class="literal">true</span> &#125;</div><div class="line">    &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="将事物状态记录到账户信息中"><a href="#将事物状态记录到账户信息中" class="headerlink" title="将事物状态记录到账户信息中"></a>将事物状态记录到账户信息中</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t.source, <span class="attr">pendingTransactions</span>: &#123; <span class="attr">$ne</span>: t._id &#125; &#125;,</div><div class="line">   &#123; <span class="attr">$inc</span>: &#123; <span class="attr">balance</span>: -t.value &#125;, <span class="attr">$push</span>: &#123; <span class="attr">pendingTransactions</span>: t._id &#125; &#125;</div><div class="line">)</div><div class="line"></div><div class="line">db.accounts.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t.destination, <span class="attr">pendingTransactions</span>: &#123; <span class="attr">$ne</span>: t._id &#125; &#125;,</div><div class="line">   &#123; <span class="attr">$inc</span>: &#123; <span class="attr">balance</span>: t.value &#125;, <span class="attr">$push</span>: &#123; <span class="attr">pendingTransactions</span>: t._id &#125; &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="将转账事务状态由pending改为applied"><a href="#将转账事务状态由pending改为applied" class="headerlink" title="将转账事务状态由pending改为applied"></a>将转账事务状态由pending改为applied</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t._id, <span class="attr">state</span>: <span class="string">"pending"</span> &#125;,</div><div class="line">   &#123;</div><div class="line">     <span class="attr">$set</span>: &#123; <span class="attr">state</span>: <span class="string">"applied"</span> &#125;,</div><div class="line">     <span class="attr">$currentDate</span>: &#123; <span class="attr">lastModified</span>: <span class="literal">true</span> &#125;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="将事务状态从账户信息中移除"><a href="#将事务状态从账户信息中移除" class="headerlink" title="将事务状态从账户信息中移除"></a>将事务状态从账户信息中移除</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t.source, <span class="attr">pendingTransactions</span>: t._id &#125;,</div><div class="line">   &#123; <span class="attr">$pull</span>: &#123; <span class="attr">pendingTransactions</span>: t._id &#125; &#125;</div><div class="line">)</div><div class="line"></div><div class="line">db.accounts.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t.destination, <span class="attr">pendingTransactions</span>: t._id &#125;,</div><div class="line">   &#123; <span class="attr">$pull</span>: &#123; <span class="attr">pendingTransactions</span>: t._id &#125; &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="将转账事务状态由applied改为done"><a href="#将转账事务状态由applied改为done" class="headerlink" title="将转账事务状态由applied改为done"></a>将转账事务状态由applied改为done</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t._id, <span class="attr">state</span>: <span class="string">"applied"</span> &#125;,</div><div class="line">   &#123;</div><div class="line">     <span class="attr">$set</span>: &#123; <span class="attr">state</span>: <span class="string">"done"</span> &#125;,</div><div class="line">     <span class="attr">$currentDate</span>: &#123; <span class="attr">lastModified</span>: <span class="literal">true</span> &#125;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<p>以上就是整个转账流程</p>
<h2 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h2><p>转账流程不是最重要的，最重要的是从故障恢复整个转账流程。下面介绍如何从各个阶段恢复转账流程</p>
<h3 id="从pending状态恢复"><a href="#从pending状态恢复" class="headerlink" title="从pending状态恢复"></a>从<code>pending</code>状态恢复</h3><p><code>pending</code>状态就是确定要开始转账，而且已经开始更新AB账户的数据了，但是从这里到转账状态变为<code>applied</code>期间，出现了问题</p>
<p>以下是从<code>pending</code>状态恢复的过程</p>
<h4 id="找到至少30分钟都未更新的而且state是pending的转账状态"><a href="#找到至少30分钟都未更新的而且state是pending的转账状态" class="headerlink" title="找到至少30分钟都未更新的而且state是pending的转账状态"></a>找到至少30分钟都未更新的而且state是<code>pending</code>的转账状态</h4><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> dateThreshold = <span class="keyword">new</span> <span class="built_in">Date</span>();</div><div class="line">dateThreshold.setMinutes(dateThreshold.getMinutes() - <span class="number">30</span>);</div><div class="line"></div><div class="line"><span class="keyword">var</span> t = db.transactions.findOne( &#123; <span class="attr">state</span>: <span class="string">"pending"</span>, <span class="attr">lastModified</span>: &#123; <span class="attr">$lt</span>: dateThreshold &#125; &#125; );</div></pre></td></tr></table></figure>
<h4 id="然后从进行转账这一步骤重新执行即可"><a href="#然后从进行转账这一步骤重新执行即可" class="headerlink" title="然后从进行转账这一步骤重新执行即可"></a>然后从<code>进行转账</code>这一步骤重新执行即可</h4><h3 id="从applied状态恢复"><a href="#从applied状态恢复" class="headerlink" title="从applied状态恢复"></a>从<code>applied</code>状态恢复</h3><h4 id="找到至少30分钟都未更新的而且state是applied的转账状态"><a href="#找到至少30分钟都未更新的而且state是applied的转账状态" class="headerlink" title="找到至少30分钟都未更新的而且state是applied的转账状态"></a>找到至少30分钟都未更新的而且state是<code>applied</code>的转账状态</h4><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> dateThreshold = <span class="keyword">new</span> <span class="built_in">Date</span>();</div><div class="line">dateThreshold.setMinutes(dateThreshold.getMinutes() - <span class="number">30</span>);</div><div class="line"></div><div class="line"><span class="keyword">var</span> t = db.transactions.findOne( &#123; <span class="attr">state</span>: <span class="string">"applied"</span>, <span class="attr">lastModified</span>: &#123; <span class="attr">$lt</span>: dateThreshold &#125; &#125; );</div></pre></td></tr></table></figure>
<h4 id="然后从更新用户信息这一步骤重新执行即可"><a href="#然后从更新用户信息这一步骤重新执行即可" class="headerlink" title="然后从更新用户信息这一步骤重新执行即可"></a>然后从<code>更新用户信息</code>这一步骤重新执行即可</h4><h2 id="故障回滚"><a href="#故障回滚" class="headerlink" title="故障回滚"></a>故障回滚</h2><h3 id="从applied状态进行回滚"><a href="#从applied状态进行回滚" class="headerlink" title="从applied状态进行回滚"></a>从<code>applied</code>状态进行回滚</h3><p>当转账进行到<code>applied</code>状态时，不推荐回滚了，可以直接恢复这个转账事务，然后再新建一个退款的事务，把钱再转回去</p>
<h3 id="从pending状态回滚"><a href="#从pending状态回滚" class="headerlink" title="从pending状态回滚"></a>从<code>pending</code>状态回滚</h3><h4 id="将转账状态更新为canceling"><a href="#将转账状态更新为canceling" class="headerlink" title="将转账状态更新为canceling"></a>将转账状态更新为<code>canceling</code></h4><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t._id, <span class="attr">state</span>: <span class="string">"pending"</span> &#125;,</div><div class="line">   &#123;</div><div class="line">     <span class="attr">$set</span>: &#123; <span class="attr">state</span>: <span class="string">"canceling"</span> &#125;,</div><div class="line">     <span class="attr">$currentDate</span>: &#123; <span class="attr">lastModified</span>: <span class="literal">true</span> &#125;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h4 id="取消AB账户的信息修改"><a href="#取消AB账户的信息修改" class="headerlink" title="取消AB账户的信息修改"></a>取消AB账户的信息修改</h4><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t.destination, <span class="attr">pendingTransactions</span>: t._id &#125;,</div><div class="line">   &#123;</div><div class="line">     <span class="attr">$inc</span>: &#123; <span class="attr">balance</span>: -t.value &#125;,</div><div class="line">     <span class="attr">$pull</span>: &#123; <span class="attr">pendingTransactions</span>: t._id &#125;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t.source, <span class="attr">pendingTransactions</span>: t._id &#125;,</div><div class="line">   &#123;</div><div class="line">     <span class="attr">$inc</span>: &#123; <span class="attr">balance</span>: t.value&#125;,</div><div class="line">     <span class="attr">$pull</span>: &#123; <span class="attr">pendingTransactions</span>: t._id &#125;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h4 id="将转账状态改为canceled"><a href="#将转账状态改为canceled" class="headerlink" title="将转账状态改为canceled"></a>将转账状态改为<code>canceled</code></h4><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(</div><div class="line">   &#123; <span class="attr">_id</span>: t._id, <span class="attr">state</span>: <span class="string">"canceling"</span> &#125;,</div><div class="line">   &#123;</div><div class="line">     <span class="attr">$set</span>: &#123; <span class="attr">state</span>: <span class="string">"cancelled"</span> &#125;,</div><div class="line">     <span class="attr">$currentDate</span>: &#123; <span class="attr">lastModified</span>: <span class="literal">true</span> &#125;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h2 id="多个应用冲突考虑"><a href="#多个应用冲突考虑" class="headerlink" title="多个应用冲突考虑"></a>多个应用冲突考虑</h2><p>通常来说，事务的存在，就能保证多个应用共同启动而且不会影响到数据的一致性。上述的两段提交过程中，根据<code>state</code>字段的值去更新事务状态，就能保证在多应用情况下重复操作产生的问题。（因为mongodb的单条更新操作是原子性的，一条更新成功了，其他所有基于<code>state</code>的查询没法查到数据）</p>
<p>举个例子：app1和app2同时去更新一个转账事务的状态，但是app1先于app2，当app1更新完成之后，事务状态已经被更新为<code>pending</code>，这时候app2再去更新，会因为查询条件不匹配而终止当前事务的执行。</p>
<p>简单来说，解决多应用问题最重要的一点就是保证在同一时刻，同一个事物只能由同一个应用处理。为了保证这一点，可以加一个功能类似于<code>state</code>的字段<code>application</code>，用于标识当前事务属于哪个应用。</p>
<p>例如下面的代码，将事务由<code>initial</code>状态改为<code>pending</code>状态<br><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">t = db.transactions.findAndModify(</div><div class="line">       &#123;</div><div class="line">         <span class="attr">query</span>: &#123; <span class="attr">state</span>: <span class="string">"initial"</span>, <span class="attr">application</span>: &#123; <span class="attr">$exists</span>: <span class="literal">false</span> &#125; &#125;,</div><div class="line">         <span class="attr">update</span>:</div><div class="line">           &#123;</div><div class="line">             <span class="attr">$set</span>: &#123; <span class="attr">state</span>: <span class="string">"pending"</span>, <span class="attr">application</span>: <span class="string">"App1"</span> &#125;,</div><div class="line">             <span class="attr">$currentDate</span>: &#123; <span class="attr">lastModified</span>: <span class="literal">true</span> &#125;</div><div class="line">           &#125;,</div><div class="line">         <span class="attr">new</span>: <span class="literal">true</span></div><div class="line">       &#125;</div><div class="line">    )</div></pre></td></tr></table></figure></p>
<p>如果本次事务执行失败了，可以使用上面的恢复步骤进行恢复，但是必须保证恢复时也是由原来的应用去执行，例如<br><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> dateThreshold = <span class="keyword">new</span> <span class="built_in">Date</span>();</div><div class="line">dateThreshold.setMinutes(dateThreshold.getMinutes() - <span class="number">30</span>);</div><div class="line"></div><div class="line">db.transactions.find(</div><div class="line">   &#123;</div><div class="line">     <span class="attr">application</span>: <span class="string">"App1"</span>,</div><div class="line">     <span class="attr">state</span>: <span class="string">"pending"</span>,</div><div class="line">     <span class="attr">lastModified</span>: &#123; <span class="attr">$lt</span>: dateThreshold &#125;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是通过两步提交在mongodb中实现多谢如操作事务的原型，在生产环境中情况可能会更加复杂，所以必须根据实际情况而定</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><a href="https://docs.mongodb.com/manual/tutorial/perform-two-phase-commits/" title="Perform Two Phase Commits" target="_blank" rel="external">mogodb doc Perform Two Phase Commits</a>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h2&gt;&lt;p&gt;mongodb所有的针对单个文档的操作都具有原子性，但是当一个操作涉及多个文档更新的时候，是非原子性的。但在生产环境中，是存在多文档更新的需求的，一般情况下，包含以下两个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原子性：如果任何一个操作失败，所有已经进行的操作全部回滚，并且中断接下来的所有操作&lt;/li&gt;
&lt;li&gt;一致性：如果操作执行过程遭遇中断，例如断电，数据库要有能力保持数据一致性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了解决多文档更新事务性问题，可以使用两段提交的方式处理。两段提交可以保证数据是一致的，而且可以保证遇到错误之后可以恢复，但是在执行期间，文档本身处于待定状态&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：因为mongodb只有单文档操作具有事务性，两段提交只能提供类似原子操作的语义，而不是提供完善的事务机制&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="mongodb" scheme="http://cocacola183.github.io/categories/mongodb/"/>
    
    
      <category term="mongodb" scheme="http://cocacola183.github.io/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>mongos cursor 的使用</title>
    <link href="http://cocacola183.github.io/2017/06/01/node/mongos-cursor-%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://cocacola183.github.io/2017/06/01/node/mongos-cursor-的使用/</id>
    <published>2017-06-01T10:35:07.000Z</published>
    <updated>2017-07-02T12:31:05.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><div style="text-align:center">
  <div class="github-card" data-user="Automattic" data-repo="mongoose" data-width="100%" data-theme="default" data-target="" data-client-id="" data-client-secret=""></div>
</div>
<script src="/github-card-lib/githubcard.js"></script>

<p><code>mongoose</code>在github上是一个很受欢迎的开源项目，作为加强版的mongo node driver，有很多优点，但是无奈文档不怎么全面，下面是一些关于<code>mongoose cursor</code>的用法总结</p>
<a id="more"></a>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>node 6.9.1</li>
<li>mongoose 4.11.0 （如果可能，尽量用新版，开源的东西，你懂的）</li>
</ul>
<h2 id="cursor基础"><a href="#cursor基础" class="headerlink" title="cursor基础"></a>cursor基础</h2><p><a href="https://docs.mongodb.com/v3.0/core/cursors/" target="_blank" rel="external">参考链接</a></p>
<h3 id="cursor生命周期"><a href="#cursor生命周期" class="headerlink" title="cursor生命周期"></a>cursor生命周期</h3><p>cursor就是mongodb查询游标，利用它可以返回所有的查询结果，可以一次性返回，可以分批返回。</p>
<p>默认情况下，查询游标的生存周期是10分钟，如果在这期间，cursor耗尽（已经返回了所有结果），mongo server也会关闭这个cursor。cursor有选项noTimeout，可以阻止这个默认行为，如果使用了这个选项，就必须要手动关闭cursor或者是药最终有能力耗尽这个cursor。</p>
<h3 id="cursor隔离性"><a href="#cursor隔离性" class="headerlink" title="cursor隔离性"></a>cursor隔离性</h3><p>cursor使用过程当中肯定存在一些其他的操作会影响正在查询的数据，如果使用的饰mmapv1存储引擎，在某些情况下，会导致同一个document返回多次的情况，关于这一些，官方文档有详细的说明，建议大家早日更换wt</p>
<blockquote><p>As a cursor returns documents other operations may interleave with the query: with MMAPv1 storage engine, if some of these operations are updates that cause the document to move (in the case of a table scan, caused by document growth) or that change the indexed field on the index used by the query; then the cursor will return the same document more than once.</p>
<footer><strong>Mongodb doc</strong><cite><a href="https://docs.mongodb.com/v3.0/faq/developers/#faq-developers-isolate-cursors" target="_blank" rel="external">docs.mongodb.com/v3.0/faq/developers/#faq-developers-isolate-cursors</a></cite></footer></blockquote>
<h3 id="cursor-batch"><a href="#cursor-batch" class="headerlink" title="cursor batch"></a>cursor batch</h3><p>使用游标获取数据的时候，数据是分批返回的。每一批数据不能超过<a href="https://docs.mongodb.com/v3.0/reference/limits/#limit-bson-document-size" target="_blank" rel="external">maximum BSON document size</a>，默认情况下，第一批数据返回101条数据或者不超过1MB的数据，之后每次返回4M数据。可以手动设定batch size</p>
<h2 id="mongoose中使用cusror"><a href="#mongoose中使用cusror" class="headerlink" title="mongoose中使用cusror"></a>mongoose中使用cusror</h2><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> cursor = UserModel.find(&#123;<span class="attr">name</span>: <span class="string">'kivi'</span>&#125;).cursor(&#123;<span class="attr">batchSize</span>: <span class="number">100</span>&#125;);</div><div class="line">cursor.on(<span class="string">'data'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">doc</span>) </span>&#123;</div><div class="line">  <span class="comment">// do something</span></div><div class="line">&#125;);</div><div class="line">cursor.on(<span class="string">'end'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">doc</span>) </span>&#123;</div><div class="line">    <span class="built_in">console</span>.log(<span class="string">'cursor exausted'</span>;</div><div class="line">&#125;);</div><div class="line">cursor.on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</div><div class="line">    <span class="built_in">console</span>.log(<span class="string">'got error'</span>, err);</div><div class="line">&#125;);</div></pre></td></tr></table></figure>
<p>一开始我也想着应该有什么方法能一次性拿到一个batch的数据，最终发现数据还是会一条一条的过来<br><blockquote><p>Batch sizes are just for performance optimisation and will not give you a 50 object chunk.<br>You will still have to process each doc individually.</p>
<footer><strong>stackoverflow</strong><cite><a href="https://stackoverflow.com/questions/42118590/mongoose-cursor-batchsize" target="_blank" rel="external">stackoverflow.com/questions/42118590/mongoose-cursor-batchsize</a></cite></footer></blockquote></p>
<h3 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h3><p>正常情况下，这么用是没问题的<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> cursor = model.aggregate(parameters).cursor(&#123; <span class="attr">batchSize</span>: <span class="number">1000</span> &#125;).exec();</div><div class="line">cursor.on(<span class="string">'data'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">doc</span>) </span>&#123;</div><div class="line">  <span class="comment">// do something</span></div><div class="line">&#125;);</div><div class="line">cursor.on(<span class="string">'end'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">doc</span>) </span>&#123;</div><div class="line">    <span class="built_in">console</span>.log(<span class="string">'cursor exausted'</span>;</div><div class="line">&#125;);</div><div class="line">cursor.on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</div><div class="line">&#125;);</div></pre></td></tr></table></figure></p>
<p>但是上面的写法有的时候cursor是null，这是mongoose的一个bug，连接没有完全建立的时候就会出现这种情况</p>
<blockquote><p>It’s unfortunately a bug with the first way we implemented aggregation cursors - cursor will be undefined if the model’s underlying connection has not successfully connected. That’s what the async option for agg cursors is for:</p>
<p>model.aggregate(parameters).cursor({ batchSize: 1000, async: true }).exec(function(error, cursor) {<br>  // Can now use cursor<br>});<br>The reason why it needs to be async is that mongoose may need to wait for the connection to mongodb to be established before it can actually return the cursor.</p>
<footer><strong>mongoose</strong><cite><a href="https://github.com/Automattic/mongoose/issues/4694" target="_blank" rel="external">github.com/Automattic/mongoose/issues/4694</a></cite></footer></blockquote>
<p>所以下面的async参数非常有意义</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">UserModel</div><div class="line">  .aggregate()</div><div class="line">  .cursor(&#123; <span class="attr">batchSize</span>: <span class="number">100</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;)</div><div class="line">  .exec(<span class="function"><span class="keyword">function</span> (<span class="params">err, cursor</span>) </span>&#123;</div><div class="line">      cursor.on(<span class="string">'data'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">doc</span>) </span>&#123;</div><div class="line"></div><div class="line">      &#125;);</div><div class="line">      cursor.on(<span class="string">'end'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</div><div class="line">      &#125;);</div><div class="line">      cursor.on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</div><div class="line"></div><div class="line">      &#125;);</div><div class="line">    &#125;);</div></pre></td></tr></table></figure>
<p>以上是mongoose cursor使用的两个最基本的场景，以后会补充更多关于cursor更加丰富的用法</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;div style=&quot;text-align:center&quot;&gt;
  &lt;div class=&quot;github-card&quot; data-user=&quot;Automattic&quot; data-repo=&quot;mongoose&quot; data-width=&quot;100%&quot; data-theme=&quot;default&quot; data-target=&quot;&quot; data-client-id=&quot;&quot; data-client-secret=&quot;&quot;&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;script src=&quot;/github-card-lib/githubcard.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;code&gt;mongoose&lt;/code&gt;在github上是一个很受欢迎的开源项目，作为加强版的mongo node driver，有很多优点，但是无奈文档不怎么全面，下面是一些关于&lt;code&gt;mongoose cursor&lt;/code&gt;的用法总结&lt;/p&gt;
    
    </summary>
    
      <category term="Node.js" scheme="http://cocacola183.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="http://cocacola183.github.io/tags/Node-js/"/>
    
      <category term="mongoose" scheme="http://cocacola183.github.io/tags/mongoose/"/>
    
  </entry>
  
  <entry>
    <title>mongodb常用命令整理</title>
    <link href="http://cocacola183.github.io/2017/05/22/mongo/mongodb%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"/>
    <id>http://cocacola183.github.io/2017/05/22/mongo/mongodb常用命令整理/</id>
    <published>2017-05-22T00:29:08.000Z</published>
    <updated>2017-07-02T12:43:40.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="慢查询相关"><a href="#慢查询相关" class="headerlink" title="慢查询相关"></a>慢查询相关</h2><h3 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a><a href="https://blog.mlab.com/2014/02/mongodb-currentop-killop/" target="_blank" rel="external">慢查询</a></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.currentOp().inprog.forEach(</div><div class="line">  function(op) &#123;</div><div class="line">    if(op.secs_running &gt; 5) printjson(op);</div><div class="line">  &#125;</div><div class="line">)</div><div class="line"></div><div class="line">db.killOp(opid) // kill op</div></pre></td></tr></table></figure>
<p><a href="http://ultrasql.blog.51cto.com/9591438/1706481" target="_blank" rel="external">返回参数详解</a></p>
<a id="more"></a>
<h2 id="wiredtiger相关"><a href="#wiredtiger相关" class="headerlink" title="wiredtiger相关"></a>wiredtiger相关</h2><h3 id="查看mongodb-cache-size-bytes"><a href="#查看mongodb-cache-size-bytes" class="headerlink" title="查看mongodb cache size(bytes)"></a>查看mongodb cache size(bytes)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.runCommand( &#123; serverStatus: 1 &#125; ).wiredTiger.cache["bytes currently in the cache"]</div></pre></td></tr></table></figure>
<h3 id="查看mongodb内存占用-MB"><a href="#查看mongodb内存占用-MB" class="headerlink" title="查看mongodb内存占用(MB)"></a>查看mongodb内存占用(MB)</h3><h4 id="mongo-shell"><a href="#mongo-shell" class="headerlink" title="mongo shell"></a>mongo shell</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.runCommand( &#123; serverStatus: 1, workingSet: 1 &#125; ).mem.resident</div></pre></td></tr></table></figure>
<h4 id="linux-shell-最后一列是实际物理内存占用"><a href="#linux-shell-最后一列是实际物理内存占用" class="headerlink" title="linux shell(最后一列是实际物理内存占用)"></a>linux shell(最后一列是实际物理内存占用)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ps -e -o 'pid,comm,rsz'</div></pre></td></tr></table></figure>
<h4 id="查看系统缺页信息"><a href="#查看系统缺页信息" class="headerlink" title="查看系统缺页信息"></a><a href="https://github.com/chyyuu/ucore_os_lab/blob/master/related_info/lab2/watch_linux_pagefault.md" target="_blank" rel="external">查看系统缺页信息</a></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ps -eo min_flt,maj_flt,pid,%cpu,%mem,pagein,args  --sort=min_flt | grep mongo</div></pre></td></tr></table></figure>
<h2 id="数据chunk相关"><a href="#数据chunk相关" class="headerlink" title="数据chunk相关"></a>数据chunk相关</h2><h3 id="查看chunk大小"><a href="#查看chunk大小" class="headerlink" title="查看chunk大小"></a>查看chunk大小</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">var ns = "test.test"</div><div class="line">var key = &#123;account:1&#125; </div><div class="line"></div><div class="line">db.getSiblingDB("config").chunks.find(&#123;ns : ns&#125;).forEach(function(chunk) &#123;</div><div class="line">        var ds = db.getSiblingDB(ns.split(".")[0]).runCommand(&#123;datasize:chunk.ns,keyPattern:key,min:chunk.min,max:chunk.max&#125;);</div><div class="line">        print("Chunk: "+chunk._id +" has a size of "+ds.size+", and includes "+ds.numObjects+" objects (took "+ds.millis+"ms)")</div><div class="line">    &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="查询并切分大chunk"><a href="#查询并切分大chunk" class="headerlink" title="查询并切分大chunk"></a>查询并切分大chunk</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">sh.stopBalancer()</div><div class="line"></div><div class="line">use config</div><div class="line">db.chunks.find(&#123;"ns": "test.user", jumbo: true&#125;)</div><div class="line"></div><div class="line">sh.splitAt("db.collection", &#123; account: "shardkey" &#125;)</div><div class="line"></div><div class="line">sh.splitFind("db.collection", &#123; account: "shardkey" &#125;)</div><div class="line"></div><div class="line">sh.moveChunk("db.collection", &#123; shardkey:"shardkey所在的块" &#125;, "需要移动的目标分片ID")</div><div class="line"></div><div class="line">sh.startBalancer()</div></pre></td></tr></table></figure>
<h2 id="Balancer"><a href="#Balancer" class="headerlink" title="Balancer"></a>Balancer</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">use config</div><div class="line">db.settings.update(</div><div class="line">  &#123; _id: "balancer" &#125;,</div><div class="line">  &#123; $set: &#123; activeWindow : &#123; start: "23:00", stop: "6:00" &#125; &#125; &#125;,</div><div class="line">  &#123; upsert: true &#125;</div><div class="line"></div><div class="line">)</div></pre></td></tr></table></figure>
<h2 id="数据库迁移"><a href="#数据库迁移" class="headerlink" title="数据库迁移"></a>数据库迁移</h2><h3 id="js-shell"><a href="#js-shell" class="headerlink" title="js + shell"></a>js + shell</h3><p><a href="https://gist.github.com/bradvogel/f08c520887f3081a1e5dbc0f86531c7f#file-livesync-js" target="_blank" rel="external">迁移脚本</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;慢查询相关&quot;&gt;&lt;a href=&quot;#慢查询相关&quot; class=&quot;headerlink&quot; title=&quot;慢查询相关&quot;&gt;&lt;/a&gt;慢查询相关&lt;/h2&gt;&lt;h3 id=&quot;慢查询&quot;&gt;&lt;a href=&quot;#慢查询&quot; class=&quot;headerlink&quot; title=&quot;慢查询&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://blog.mlab.com/2014/02/mongodb-currentop-killop/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;慢查询&lt;/a&gt;&lt;/h3&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;db.currentOp().inprog.forEach(&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  function(op) &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    if(op.secs_running &amp;gt; 5) printjson(op);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;db.killOp(opid) // kill op&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;http://ultrasql.blog.51cto.com/9591438/1706481&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;返回参数详解&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mongodb" scheme="http://cocacola183.github.io/categories/mongodb/"/>
    
    
      <category term="mongodb" scheme="http://cocacola183.github.io/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>mongodb固定大小表</title>
    <link href="http://cocacola183.github.io/2017/05/09/mongo/mongodb%E5%9B%BA%E5%AE%9A%E5%A4%A7%E5%B0%8F%E8%A1%A8/"/>
    <id>http://cocacola183.github.io/2017/05/09/mongo/mongodb固定大小表/</id>
    <published>2017-05-09T07:59:26.000Z</published>
    <updated>2017-07-02T02:33:19.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h2><p><code>Capped collection</code>（固定大小表）是一种大小为可设定的固定值的集合。支持高性能写入操作和高性能以插入顺序读操作。<code>Capped collection</code>原理类似循环缓冲区，当达到最大限制时，会覆盖最老的数据用以写入新的数据。</p>
<h2 id="有什么特性"><a href="#有什么特性" class="headerlink" title="有什么特性"></a>有什么特性</h2><ul>
<li>大小固定可设定</li>
<li>提供高性能的写入操作，高性能的基于插入顺序的读操作</li>
</ul>
<h2 id="什么时候需要用"><a href="#什么时候需要用" class="headerlink" title="什么时候需要用"></a>什么时候需要用</h2><p>下面列举两个常见场景</p>
<h3 id="日志写入"><a href="#日志写入" class="headerlink" title="日志写入"></a>日志写入</h3><p>在大磁盘容量的系统中，在没有索引的前提下，以接近写日志文件的速度存储日志到<code>Capped collection</code>中。而且自带先进先出的磁盘空间使用策略</p>
<h3 id="缓存少量数据"><a href="#缓存少量数据" class="headerlink" title="缓存少量数据"></a>缓存少量数据</h3><p>缓存属于读取压力大，写入压力小的操作，如果不使用<code>Capped collection</code>，你就会面临两种选择</p>
<ul>
<li>牺牲写入性能，添加索引</li>
<li>让这部分数据常驻内存（占用内存空间）</li>
</ul>
<a id="more"></a>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><h3 id="更新操作"><a href="#更新操作" class="headerlink" title="更新操作"></a>更新操作</h3><p>如果固定大小表会有更新操作，请先创建索引避免一次更新操作会扫描整个表</p>
<p>使用MMAPv1存储引擎的时候，如果有更新操作导致数据增长超过固定大小表的限制，更新将会失败</p>
<h3 id="使用MMAPv1存储引擎的副本集从节点"><a href="#使用MMAPv1存储引擎的副本集从节点" class="headerlink" title="使用MMAPv1存储引擎的副本集从节点"></a>使用MMAPv1存储引擎的副本集从节点</h3><p>如果主节点将固定大小表的size改小了，从节点也会随之改小</p>
<p>更新操作如果会让<code>Capped collection</code>超出配置的大小，primary节点会执行成功，secondary节点如果使用的是MMAPv1存储引擎，就会导致出现<code>failing update: objects in a capped ns cannot grow</code>的错误信息<br>为了解决这个问题，可以按照<a href="https://docs.mongodb.com/v3.0/tutorial/backup-with-filesystem-snapshots/" target="_blank" rel="external">这个教程</a>去处理secondary节点。<br>简单来说，方法就是把primary的数据目录复制一遍作为secondary的数据目录</p>
<h3 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h3><p><code>Capped collection</code>无法删除部分文档，如果要删数据，只能drop掉表，然后新建一个新的<code>Capped collection</code></p>
<h3 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h3><p><code>Capped collection</code>不能被分片</p>
<h3 id="Aggregation-out"><a href="#Aggregation-out" class="headerlink" title="Aggregation $out"></a>Aggregation $out</h3><p>聚合操作的$out操作符输出数据不能输出到<code>Capped collection</code></p>
<h2 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.createCollection( "log", &#123; capped: true, size: 100000 &#125; ) // size的单位bytes</div></pre></td></tr></table></figure>
<ul>
<li>以上两个参数是必要参数</li>
<li><code>Capped collection</code>实际占用空间大小会略微大于配置的maxsize，因为有一些磁盘空间用于内部开销</li>
<li>如果size小于4096那么，<code>Capped collection</code>将认为size是4096，如果size大于4096，<code>Capped collection</code>会自动让size整除256</li>
</ul>
<p>也可以指定最大的document数量，例如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.createCollection(&quot;log&quot;, &#123; capped : true, size : 5242880, max : 5000 &#125; )</div></pre></td></tr></table></figure></p>
<blockquote>
<p>size是必传参数，size的优先级高于max</p>
</blockquote>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.cappedCollection.find().sort( &#123; $natural: -1 &#125; )</div></pre></td></tr></table></figure>
<p>上例是按照文档插入顺序倒排查询</p>
<h3 id="检查是否是Capped-collection"><a href="#检查是否是Capped-collection" class="headerlink" title="检查是否是Capped collection"></a>检查是否是<code>Capped collection</code></h3><p>db.collection.isCapped()</p>
<h3 id="将一个非Capped-collection转换为Capped-collection"><a href="#将一个非Capped-collection转换为Capped-collection" class="headerlink" title="将一个非Capped collection转换为Capped collection"></a>将一个非<code>Capped collection</code>转换为<code>Capped collection</code></h3><p>db.runCommand({“convertToCapped”: “mycoll”, size: 100000});</p>
<blockquote>
<p><span style="color: red">警告：这个命令会创建一个全局写锁，并且会阻塞其他操作一直到命令结束</span></p>
<p><span style="color: red">注意：分片集群不支持<code>convertToCapped</code>命令</span></p>
</blockquote>
<h3 id="设置自动删除数据的延迟时间"><a href="#设置自动删除数据的延迟时间" class="headerlink" title="设置自动删除数据的延迟时间"></a>设置自动删除数据的延迟时间</h3><p>如果想设置自动删除数据的延迟时间，可以参考mongodb的<a href="https://docs.mongodb.com/v3.0/reference/glossary/#term-ttl" target="_blank" rel="external">TTL索引</a>机制。遗憾的是TTL集合跟<code>Capped collection</code>并不兼容（没搞懂官网提这个搞什么）</p>
<h3 id="Tailable-Cursor"><a href="#Tailable-Cursor" class="headerlink" title="Tailable Cursor"></a>Tailable Cursor</h3><p><a href="https://docs.mongodb.com/v3.0/reference/glossary/#term-tailable-cursor" target="_blank" rel="external">tailable cursor</a>有点类似Unix命令<code>tail -f</code>，会跟踪文件新写入的内容，使用<code>tailable cursor</code>可以跟踪新插入到<code>Capped collection</code>中的数据</p>
<h2 id="其他相关概念"><a href="#其他相关概念" class="headerlink" title="其他相关概念"></a>其他相关概念</h2><h3 id="写入顺序"><a href="#写入顺序" class="headerlink" title="写入顺序"></a>写入顺序</h3><p><code>Capped collection</code>会保存数据写入顺序，所以如果返回数据顺序就是数据插入顺序，查询的时候不需要额外的索引去控制，<code>Capped collection</code>会自动以插入顺序返回。这种方式比使用索引有更好的性能</p>
<h3 id="旧数据的自动清除"><a href="#旧数据的自动清除" class="headerlink" title="旧数据的自动清除"></a>旧数据的自动清除</h3><p><code>Capped collection</code>会自动删除最老的数据，为新来的数据腾出空间，不需要代码控制</p>
<h3 id="id索引"><a href="#id索引" class="headerlink" title="_id索引"></a>_id索引</h3><p>2.4以及2.4以上的变更<br>固定大小表默认有_id字段，而且会默认在_id字段创建索引</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;是什么&quot;&gt;&lt;a href=&quot;#是什么&quot; class=&quot;headerlink&quot; title=&quot;是什么&quot;&gt;&lt;/a&gt;是什么&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Capped collection&lt;/code&gt;（固定大小表）是一种大小为可设定的固定值的集合。支持高性能写入操作和高性能以插入顺序读操作。&lt;code&gt;Capped collection&lt;/code&gt;原理类似循环缓冲区，当达到最大限制时，会覆盖最老的数据用以写入新的数据。&lt;/p&gt;
&lt;h2 id=&quot;有什么特性&quot;&gt;&lt;a href=&quot;#有什么特性&quot; class=&quot;headerlink&quot; title=&quot;有什么特性&quot;&gt;&lt;/a&gt;有什么特性&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;大小固定可设定&lt;/li&gt;
&lt;li&gt;提供高性能的写入操作，高性能的基于插入顺序的读操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;什么时候需要用&quot;&gt;&lt;a href=&quot;#什么时候需要用&quot; class=&quot;headerlink&quot; title=&quot;什么时候需要用&quot;&gt;&lt;/a&gt;什么时候需要用&lt;/h2&gt;&lt;p&gt;下面列举两个常见场景&lt;/p&gt;
&lt;h3 id=&quot;日志写入&quot;&gt;&lt;a href=&quot;#日志写入&quot; class=&quot;headerlink&quot; title=&quot;日志写入&quot;&gt;&lt;/a&gt;日志写入&lt;/h3&gt;&lt;p&gt;在大磁盘容量的系统中，在没有索引的前提下，以接近写日志文件的速度存储日志到&lt;code&gt;Capped collection&lt;/code&gt;中。而且自带先进先出的磁盘空间使用策略&lt;/p&gt;
&lt;h3 id=&quot;缓存少量数据&quot;&gt;&lt;a href=&quot;#缓存少量数据&quot; class=&quot;headerlink&quot; title=&quot;缓存少量数据&quot;&gt;&lt;/a&gt;缓存少量数据&lt;/h3&gt;&lt;p&gt;缓存属于读取压力大，写入压力小的操作，如果不使用&lt;code&gt;Capped collection&lt;/code&gt;，你就会面临两种选择&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;牺牲写入性能，添加索引&lt;/li&gt;
&lt;li&gt;让这部分数据常驻内存（占用内存空间）&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="mongodb" scheme="http://cocacola183.github.io/categories/mongodb/"/>
    
    
      <category term="mongodb" scheme="http://cocacola183.github.io/tags/mongodb/"/>
    
  </entry>
  
</feed>
